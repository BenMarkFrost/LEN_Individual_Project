{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from torch_explain.models.explainer import Explainer\n",
    "from torch_explain.logic.metrics import formula_consistency\n",
    "# from load_datasets import load_mimic\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from torch.nn.functional import one_hot\n",
    "from func_timeout import func_set_timeout, func_timeout, FunctionTimedOut\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "seed_everything(42)\n",
    "base_dir = f'./runs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['breastCancer.csv', 'clusteredData.csv', 'clusteredDataSepsis.csv', 'expertLabelledData.csv', 'metricExtractedData.csv', 'staticData.csv']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"./categorisedData/\")\n",
    "\n",
    "\n",
    "datasets = {file : pd.read_csv(\"./categorisedData/\" + file) for file in files}\n",
    "\n",
    "\n",
    "print(files)\n",
    "\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_set_timeout(90)\n",
    "def explain_with_timeout(model, val_data, train_data, test_data, topk_expl, concepts):\n",
    "\n",
    "    return model.explain_class(val_dataloaders=val_data, train_dataloaders=train_data, test_dataloaders=test_data, topk_explanations=topk_expl, concept_names=concepts, max_minterm_complexity=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes in each hidden layer, learning rate\n",
    "\n",
    "hiddenLayers = {\n",
    "    'breastCancer.csv' : [[20], 0.01],\n",
    "    'clusteredData.csv' : [[10], 0.01], \n",
    "    'clusteredDataSepsis.csv' : [[20, 40, 20], 0.0001],\n",
    "    'expertLabelledData.csv' : [[20], 0.01],\n",
    "    'metricExtractedData.csv' : [[20, 20], 0.01],\n",
    "    'staticData.csv': [[20], 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training clusteredDataSepsis.csv\n",
      "\n",
      "0    31606\n",
      "1     2422\n",
      "Name: Mortality14Days, dtype: int64\n",
      "There are 72 concepts\n",
      "Split [1/5]\n",
      "21777/5445/6806\n",
      "[20225  1552]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:57: LightningDeprecationWarning: Setting `Trainer(weights_save_path=)` has been deprecated in v1.6 and will be removed in v1.8. Please pass ``dirpath`` directly to the `ModelCheckpoint` callback\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:611: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Notebooks\\runs exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14768 13050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.6 K \n",
      "-------------------------------------------\n",
      "4.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Metric val_loss improved. New best score: 0.669\n",
      "Metric val_loss improved by 0.051 >= min_delta = 0.0. New best score: 0.618\n",
      "Metric val_loss improved by 0.029 >= min_delta = 0.0. New best score: 0.589\n",
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.589\n",
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.588\n",
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.573\n",
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.573. Signaling Trainer to stop.\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loading best: [0.5270557005378721, 0.6531393062661937, 0.5489363681944676]\n",
      "clusteredDataSepsis.csv split 1 scores: [0.5270557005378721, 0.6531393062661937, 0.5489363681944676]\n",
      "\n",
      "Testing...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      f1_test_epoch         0.5330842137336731\n",
      "     test_acc_epoch         0.7358213067054749\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Explaining\n",
      "\n",
      "Explaining time: 5.772283554077148\n",
      "Number of features that impact on target 0: 58\n",
      "Explanation for target 0: ~O2Sat_StdDev_high & ~Potassium_Mean_low & ~Temp_StdDev_high\n",
      "Explanation accuracy: 0.5589558231892459\n",
      "Number of features that impact on target 1: 50\n",
      "Explanation for target 1: Temp_StdDev_high | ICULOS_high\n",
      "Explanation accuracy: 0.5714128762909251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# print(os.listdir(\".\"))\n",
    "\n",
    "\n",
    "for file in files[:1]:\n",
    "\n",
    "    file = \"clusteredDataSepsis.csv\"\n",
    "\n",
    "    if file in hiddenLayers:\n",
    "        layers = hiddenLayers[file]\n",
    "    else:\n",
    "        print(\"Set layers for \" + file)\n",
    "        layers = [[20], 0.01]\n",
    "\n",
    "    print(f\"Training {file}\\n\")\n",
    "\n",
    "    data = datasets[file]\n",
    "\n",
    "    if \"PatientID\" in data.columns:\n",
    "        data = data.drop(columns=[\"PatientID\"])\n",
    "\n",
    "\n",
    "    targetName = \"Mortality14Days\"\n",
    "\n",
    "    targetSeries = data[targetName]\n",
    "    print(data[targetName].value_counts())\n",
    "    data = data.drop(columns=[targetName])\n",
    "    \n",
    "    dataTensor = torch.FloatTensor(data.to_numpy())\n",
    "    targetTensor = one_hot(torch.tensor(targetSeries.values).to(torch.long)).to(torch.float)\n",
    "\n",
    "    n_concepts = dataTensor.shape[1]\n",
    "    print(\"There are \" + str(n_concepts) + \" concepts\")\n",
    "    n_classes = 2\n",
    "    # print(\"feature names: \", concept_names)\n",
    "    # print(\"features:\", n_concepts)\n",
    "    # print(n_classes)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    results_list = []\n",
    "    feature_selection = []\n",
    "\n",
    "    splitResults_list = []\n",
    "\n",
    "\n",
    "    x = dataTensor\n",
    "    y = targetTensor\n",
    "\n",
    "    for split, (trainval_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(),\n",
    "                                                                y.argmax(dim=1).cpu().detach().numpy())):\n",
    "        print(f'Split [{split + 1}/{n_splits}]')\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x_trainval, x_test = torch.FloatTensor(x[trainval_index]), torch.FloatTensor(x[test_index])\n",
    "        y_trainval, y_test = torch.FloatTensor(y[trainval_index]), torch.FloatTensor(y[test_index])\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=0.2, random_state=42)\n",
    "        print(f'{len(y_train)}/{len(y_val)}/{len(y_test)}')\n",
    "\n",
    "        print(pd.Series(np.argmax(y_train.numpy(), axis=1)).value_counts().values)\n",
    "\n",
    "        # For oversampling... \n",
    "        clf = SMOTEN(random_state=0)\n",
    "\n",
    "        x_train, y_train = clf.fit_resample(x_train.numpy(), np.argmax(y_train.numpy(), axis=1))\n",
    "\n",
    "        x_train = torch.FloatTensor(x_train)\n",
    "        y_train = one_hot(torch.tensor(y_train).to(torch.long)).to(torch.float)\n",
    "\n",
    "        print(pd.Series(np.argmax(y_train.numpy(), axis=1)).value_counts().values)\n",
    "\n",
    "        batch_size = 128\n",
    "\n",
    "        train_data = TensorDataset(x_train, y_train)\n",
    "        train_loader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "        # For random sampling...\n",
    "        # class_count = pd.Series(targetSeries).value_counts()\n",
    "        # print(class_count)\n",
    "        # weights = 1. / torch.FloatTensor(class_count.values)\n",
    "        # print(weights)\n",
    "        # train_weights = np.array([weights[t] for t in torch.argmax(y_train, axis=1).numpy()]).astype(np.float64)\n",
    "        # sampler = WeightedRandomSampler(train_weights, train_size)\n",
    "        # train_data = TensorDataset(x_train, y_train)\n",
    "        # train_loader = DataLoader(train_data, batch_size=train_size, sampler=sampler)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        val_data = TensorDataset(x_val, y_val)\n",
    "        test_data = TensorDataset(x_test, y_test)\n",
    "        val_loader = DataLoader(val_data, batch_size = batch_size)\n",
    "        test_loader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(dirpath=base_dir, monitor='val_loss', mode='min', save_top_k=1)\n",
    "        early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20, verbose=True, mode='min')\n",
    "\n",
    "        logger = TensorBoardLogger(\"./runs/splits/\", name=file)\n",
    "\n",
    "        trainer = Trainer(max_epochs=200, gpus=1, auto_lr_find=True, deterministic=True,\n",
    "                        check_val_every_n_epoch=1, default_root_dir=base_dir,\n",
    "                        weights_save_path=base_dir, callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                        logger=logger, enable_progress_bar=False, gradient_clip_val=0.5)\n",
    "\n",
    "        model = Explainer(n_concepts=n_concepts, n_classes=n_classes, l1=1e-3, lr=layers[1],\n",
    "                        explainer_hidden=layers[0], temperature=0.7)\n",
    "\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        # print(f\"Gamma: {model.model[0].concept_mask}\")\n",
    "        model.freeze()\n",
    "\n",
    "        # Precision, Recall, F1\n",
    "        y_pred = torch.argmax(model(x_test), axis=1)\n",
    "        y_test_argmax = torch.argmax(y_test, axis=1)\n",
    "\n",
    "        scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                recall_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                precision_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro')]\n",
    "\n",
    "        print(f\"Before loading best: {scores}\")\n",
    "\n",
    "        # scores_list.append(scores)\n",
    "    \n",
    "        model = model.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "\n",
    "        \n",
    "\n",
    "        # Precision, Recall, F1\n",
    "\n",
    "        scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                recall_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                precision_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro')]\n",
    "\n",
    "        print(f\"{file} split {split+1} scores: {scores}\")\n",
    "\n",
    "        print(\"\\nTesting...\\n\")\n",
    "        # test_loader is giving a new batch of testing values, hence why the output here is different than above.\n",
    "        model_results = trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "\n",
    "        print(\"\\nExplaining\\n\")\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        try:\n",
    "\n",
    "            results, f = explain_with_timeout(model, val_data=val_loader, train_data=train_loader, test_data=test_loader,\n",
    "                                        topk_expl=3,\n",
    "                                        concepts=data.columns)\n",
    "\n",
    "        except FunctionTimedOut:\n",
    "            print(\"Explanation timed out, skipping...\")\n",
    "            # explanations_list.append(None)\n",
    "            # results_list.append(None)\n",
    "            continue\n",
    "\n",
    "        end = time.time()\n",
    "        # explanations_list.append(f)\n",
    "\n",
    "        print(f\"Explaining time: {end - start}\")\n",
    "        results['model_accuracy'] = model_results[0]['test_acc_epoch']\n",
    "        results['extraction_time'] = end - start\n",
    "\n",
    "        results_list.append(results)\n",
    "        extracted_concepts = []\n",
    "        all_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "        common_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "        for j in range(n_classes):\n",
    "            # print(f[j]['explanation'])\n",
    "            n_used_concepts = sum(model.model[0].concept_mask[j] > 0.5)\n",
    "            print(f\"Number of features that impact on target {j}: {n_used_concepts}\")\n",
    "            print(f\"Explanation for target {j}: {f[j]['explanation']}\")\n",
    "            print(f\"Explanation accuracy: {f[j]['explanation_accuracy']}\")\n",
    "            extracted_concepts.append(n_used_concepts)\n",
    "            all_concepts += model.model[0].concept_mask[j] > 0.5\n",
    "            common_concepts *= model.model[0].concept_mask[j] > 0.5\n",
    "\n",
    "\n",
    "        results['extracted_concepts'] = np.mean(extracted_concepts)\n",
    "        results['common_concepts_ratio'] = sum(common_concepts) / sum(all_concepts)\n",
    "\n",
    "\n",
    "\n",
    "        # prec_rec = precision_recall(y_pred, y_test_argmax, num_classes = n_classes)\n",
    "\n",
    "        # print(prec_rec)\n",
    "\n",
    "        # compare against standard feature selection\n",
    "        i_mutual_info = mutual_info_classif(x_trainval, y_trainval[:, 1])\n",
    "        i_chi2 = chi2(x_trainval, y_trainval[:, 1])[0]\n",
    "        i_chi2[np.isnan(i_chi2)] = 0\n",
    "        lasso = LassoCV(cv=5, random_state=0).fit(x_trainval, y_trainval[:, 1])\n",
    "        i_lasso = np.abs(lasso.coef_)\n",
    "        i_mu = model.model[0].concept_mask[1]\n",
    "        # print(model.model[0].concept_mask)\n",
    "        df = pd.DataFrame(np.hstack([\n",
    "            i_mu.numpy(),\n",
    "            # i_mutual_info / np.max(i_mutual_info),\n",
    "            # i_chi2 / np.max(i_chi2),\n",
    "            # i_lasso / np.max(i_lasso),\n",
    "        ]).T, columns=['feature importance'])\n",
    "        df['method'] = 'explainer'\n",
    "        # df.iloc[90:, 1] = 'MI'\n",
    "        # df.iloc[180:, 1] = 'CHI2'\n",
    "        # df.iloc[270:, 1] = 'Lasso'\n",
    "        df['feature'] = np.hstack([np.arange(0, n_concepts)])\n",
    "        feature_selection.append(df)\n",
    "\n",
    "        splitResults = [results['model_accuracy'], results['extraction_time'], *scores, f]\n",
    "\n",
    "        splitResults_list.append(splitResults)\n",
    "        break\n",
    "\n",
    "\n",
    "    results_dict[file] = splitResults_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1: 0.7089564472233105\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.argmax(model(x_train), axis=1)\n",
    "\n",
    "y = torch.argmax(y_train, axis=1)\n",
    "\n",
    "print(\"train f1:\" , f1_score(y, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1: 0.5351116208836337\n"
     ]
    }
   ],
   "source": [
    "y_pred = torch.argmax(model(x_test), axis=1)\n",
    "\n",
    "y = torch.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"test f1:\", f1_score(y, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6322,  484], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([4956, 1850], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.Series(y.numpy()).value_counts().values)\n",
    "display(pd.Series(y_pred.numpy()).value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNoneExplanations(explanations):\n",
    "\n",
    "    toRemove = []\n",
    "    for idx, expl in enumerate(explanations):\n",
    "        if expl['explanation'] == None:\n",
    "            toRemove.append(idx)\n",
    "    for i in sorted(toRemove, reverse=True):\n",
    "        # print(class0Explanations[i])\n",
    "        del explanations[i]\n",
    "\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benma\\AppData\\Local\\Temp/ipykernel_452/3778070103.py:35: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  average0 = class0DF.mean().values\n",
      "C:\\Users\\benma\\AppData\\Local\\Temp/ipykernel_452/3778070103.py:36: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  average1 = class1DF.mean().values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>expl_acc_0</th>\n",
       "      <th>expl_fidelity_0</th>\n",
       "      <th>expl_comp_0</th>\n",
       "      <th>expl_acc_1</th>\n",
       "      <th>expl_fidelity_1</th>\n",
       "      <th>expl_comp_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clusteredDataSepsis.csv</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model_acc    f1  recall  precision  expl_acc_0  \\\n",
       "file                                                                      \n",
       "clusteredDataSepsis.csv       0.74  0.53    0.65       0.55        0.56   \n",
       "\n",
       "                         expl_fidelity_0  expl_comp_0  expl_acc_1  \\\n",
       "file                                                                \n",
       "clusteredDataSepsis.csv             0.86          3.0        0.57   \n",
       "\n",
       "                         expl_fidelity_1  expl_comp_1  \n",
       "file                                                   \n",
       "clusteredDataSepsis.csv             0.85          2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kFoldMeans = []\n",
    "\n",
    "\n",
    "for x in results_dict:\n",
    "\n",
    "    cols = ['file', 'model_accuracy', 'extraction_time', 'f1', 'recall', 'precision']\n",
    "\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    class0Explanations = []\n",
    "    class1Explanations = []\n",
    "\n",
    "    for split in results_dict[x]:\n",
    "        row = [x]\n",
    "        \n",
    "        row.extend(split[:5])\n",
    "\n",
    "        # print(row)\n",
    "        rows.append(row)\n",
    "\n",
    "        class0Explanations.append(split[5][0])\n",
    "        class1Explanations.append(split[5][1])\n",
    "\n",
    "\n",
    "    class0Explanations = removeNoneExplanations(class0Explanations)\n",
    "\n",
    "    class1Explanations = removeNoneExplanations(class1Explanations)\n",
    "\n",
    "    \n",
    "\n",
    "    class0DF = pd.DataFrame(class0Explanations)\n",
    "    class1DF = pd.DataFrame(class1Explanations)\n",
    "\n",
    "    average0 = class0DF.mean().values\n",
    "    average1 = class1DF.mean().values\n",
    "\n",
    "    if len(class0Explanations) == 0:\n",
    "        average0 = [0]*4\n",
    "\n",
    "    if len(class1Explanations) == 0:\n",
    "        average1 = [0]*4\n",
    "\n",
    "    df = pd.DataFrame(columns=cols, data=rows)\n",
    "\n",
    "    df = df.set_index('file')\n",
    "\n",
    "    combinedCols = list(df.describe().columns)\n",
    "\n",
    "    # print(combinedCols)\n",
    "\n",
    "    row = [x]\n",
    "    row.extend(np.round(df.describe().loc['mean'].values, 2))\n",
    "\n",
    "    row.extend(list(average0)[1:])\n",
    "    row.extend(list(average1)[1:])\n",
    "\n",
    "    # print(row)\n",
    "\n",
    "    kFoldMeans.append(row)\n",
    "\n",
    "# print(kFoldMeans)\n",
    "\n",
    "\n",
    "\n",
    "kFoldMeansCols = list(df.describe().columns)\n",
    "\n",
    "combinedCols.insert(0, \"file\")\n",
    "\n",
    "\n",
    "# print(kFoldMeansCols)\n",
    "for idx, d in enumerate(results_dict[list(results_dict.keys())[0]][0][5]):\n",
    "    combinedCols.extend([str(x) + \"_\" + str(idx) for x in list(d)[2:]])\n",
    "\n",
    "# print(combinedCols)\n",
    "\n",
    "totalMeans = pd.DataFrame(columns=combinedCols, data=kFoldMeans)\n",
    "\n",
    "totalMeans = totalMeans.set_index('file')\n",
    "\n",
    "cols = totalMeans.columns\n",
    "\n",
    "cols = [c.replace(\"explanation\", \"expl\").replace(\"accuracy\", \"acc\").replace(\"complexity\", \"comp\") for c in cols]\n",
    "\n",
    "totalMeans.columns = cols\n",
    "\n",
    "totalMeans = totalMeans.round(2)\n",
    "\n",
    "totalMeans = totalMeans.drop(\"extraction_time\", axis=1)\n",
    "\n",
    "display(totalMeans)\n",
    "\n",
    "\n",
    "\n",
    "timeNow = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "totalMeans.to_csv(f\"./processingCache/totalMeans{timeNow}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clusteredDataSepsis.csv': [[0.7358213067054749,\n",
       "   5.772283554077148,\n",
       "   0.5270557005378721,\n",
       "   0.6531393062661937,\n",
       "   0.5489363681944676,\n",
       "   [{'target_class': 0,\n",
       "     'explanation': '~O2Sat_StdDev_high & ~Potassium_Mean_low & ~Temp_StdDev_high',\n",
       "     'explanation_accuracy': 0.5589558231892459,\n",
       "     'explanation_fidelity': 0.8565971201880693,\n",
       "     'explanation_complexity': 3},\n",
       "    {'target_class': 1,\n",
       "     'explanation': 'Temp_StdDev_high | ICULOS_high',\n",
       "     'explanation_accuracy': 0.5714128762909251,\n",
       "     'explanation_fidelity': 0.8521892447840141,\n",
       "     'explanation_complexity': 2}]]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0da8f5b93ec0612bb8aed25290fce040bcd4618fccb82f778dd001cba2969b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
