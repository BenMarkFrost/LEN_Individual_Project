{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This notebook was adapted from the following tutorial:\n",
    "https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.keras import BalancedBatchGenerator\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from tqdm import tqdm\n",
    "from tf_explain.core.grad_cam import GradCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [00:01<00:00, 904.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767, 12, 48) (767,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleanedTemporalData.csv\").set_index('PatientID')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for id, group in tqdm(df.groupby('PatientID')):\n",
    "    tempGroup = group.reset_index()\n",
    "    \n",
    "    tempGroup = tempGroup.drop(['PatientID', 'Mortality14Days'], axis=1)\n",
    "\n",
    "    tempGroup = tempGroup.fillna(0)\n",
    "\n",
    "    X.append(tempGroup.T.values)\n",
    "    y.append(group['Mortality14Days'].values[0])\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    736\n",
       "1     31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=16, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(2, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=x_train.shape[1:])\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0010822510822510823, 1: 0.02857142857142857}\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 100ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.3817 - val_loss: 0.7788 - val_sparse_categorical_accuracy: 0.3636 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.5122 - val_loss: 0.7921 - val_sparse_categorical_accuracy: 0.3182 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.6297 - val_loss: 0.7271 - val_sparse_categorical_accuracy: 0.4610 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.6933 - val_loss: 0.6523 - val_sparse_categorical_accuracy: 0.6494 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0010 - sparse_categorical_accuracy: 0.7488 - val_loss: 0.6258 - val_sparse_categorical_accuracy: 0.7078 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7330e-04 - sparse_categorical_accuracy: 0.7716 - val_loss: 0.5956 - val_sparse_categorical_accuracy: 0.7597 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.2508e-04 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.5604 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3458e-04 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.5357 - val_sparse_categorical_accuracy: 0.8831 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.8852e-04 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.5207 - val_sparse_categorical_accuracy: 0.9026 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.2172e-04 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.4985 - val_sparse_categorical_accuracy: 0.9026 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "weights = pd.Series(y).value_counts().values\n",
    "\n",
    "classWeights = {x : 1/weights[x] for x in np.unique(y)}\n",
    "\n",
    "print(classWeights)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    class_weight = classWeights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'sparse_categorical_accuracy', 'val_loss', 'val_sparse_categorical_accuracy', 'lr'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(history.history['loss'])), history.history['loss'])\n",
    "plt.plot(range(len(history.history['val_loss'])), history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5178302360622802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = np.argmax(model.predict(x_test), axis=1)\n",
    "display(f1_score(y_test, preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.77000000e+02, 1.66962963e+02, 1.58629630e+02,\n",
       "        1.52000000e+02, 1.47074074e+02, 1.43851852e+02, 1.42333333e+02,\n",
       "        1.42518519e+02, 1.44407407e+02, 1.48000000e+02, 1.53296296e+02,\n",
       "        1.60296296e+02, 1.69000000e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.20000000e+01, 4.90000000e+01, 4.20000000e+01,\n",
       "        5.70000000e+01, 6.20000000e+01, 6.00000000e+01, 5.30000000e+01,\n",
       "        5.90000000e+01, 5.90000000e+01, 5.00000000e+01, 5.50000000e+01,\n",
       "        5.20000000e+01, 5.20000000e+01, 5.30000000e+01, 5.60000000e+01,\n",
       "        5.40000000e+01, 5.20000000e+01, 4.90000000e+01, 5.30000000e+01,\n",
       "        5.40000000e+01, 5.50000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.41000000e+02, 1.11000000e+02, 1.04000000e+02,\n",
       "        1.06000000e+02, 1.08000000e+02, 1.04000000e+02, 9.50000000e+01,\n",
       "        1.01000000e+02, 1.03000000e+02, 9.10000000e+01, 1.05000000e+02,\n",
       "        9.70000000e+01, 9.60000000e+01, 9.90000000e+01, 9.40000000e+01,\n",
       "        9.80000000e+01, 9.70000000e+01, 9.80000000e+01, 9.70000000e+01,\n",
       "        8.00000000e+01, 1.11000000e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.60000000e+01, 7.20000000e+01, 7.30000000e+01,\n",
       "        7.20000000e+01, 7.60000000e+01, 7.40000000e+01, 6.60000000e+01,\n",
       "        7.30000000e+01, 7.30000000e+01, 6.30000000e+01, 7.20000000e+01,\n",
       "        6.70000000e+01, 6.80000000e+01, 6.90000000e+01, 6.80000000e+01,\n",
       "        6.70000000e+01, 6.70000000e+01, 6.60000000e+01, 6.70000000e+01,\n",
       "        5.90000000e+01, 7.20000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+01, 8.00000000e+00, 8.00000000e+00,\n",
       "        7.00000000e+00, 5.00000000e+00, 5.00000000e+00, 3.00000000e+00,\n",
       "        1.10000000e+01, 1.20000000e+01, 9.00000000e+00, 1.40000000e+01,\n",
       "        1.40000000e+01, 1.70000000e+01, 1.50000000e+01, 9.00000000e+00,\n",
       "        8.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.34000000e+00, 7.37267871e+00,\n",
       "        7.39000000e+00, 7.39196386e+00, 7.37857029e+00, 7.36089158e+00,\n",
       "        7.35000000e+00, 7.34589555e+00, 7.35000000e+00, 7.36373511e+00,\n",
       "        7.38000000e+00, 7.39169380e+00, 7.40000000e+00, 7.40610207e+00,\n",
       "        7.41000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.15000000e+01, 1.17333333e+01,\n",
       "        1.19666665e+01, 1.21999998e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.30000000e+01, 4.20735703e+01,\n",
       "        4.20000000e+01, 4.27792891e+01, 4.44114376e+01, 4.58378674e+01,\n",
       "        4.60000000e+01, 4.48978356e+01, 4.30000000e+01, 4.07751191e+01,\n",
       "        4.00000000e+01, 4.24514496e+01, 4.50000000e+01, 4.45161835e+01,\n",
       "        4.10000000e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.37000000e+02, 2.07651112e+02,\n",
       "        1.92000000e+02, 1.90046664e+02, 2.01791104e+02, 2.07889992e+02,\n",
       "        1.89000000e+02, 1.45121128e+02, 1.02000000e+02, 8.53832407e+01,\n",
       "        8.30000000e+01, 8.25794281e+01, 8.20000000e+01, 7.91401906e+01,\n",
       "        7.40000000e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.62721985e+02, 5.27919006e+02, 7.00920679e+02,\n",
       "        9.26315979e+02, 9.48693880e+02, 8.00010217e+02, 6.72000000e+02,\n",
       "        5.96619064e+02, 5.67775736e+02, 5.48919983e+02, 5.33960132e+02,\n",
       "        5.22896184e+02, 5.15728138e+02, 5.12455994e+02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.12000000e+00, 1.22000000e+00, 1.18783166e+00, 1.05494054e+00,\n",
       "        1.01000000e+00, 1.08445561e+00, 1.16000000e+00, 1.11832580e+00,\n",
       "        1.07000000e+00, 1.12558956e+00, 1.21000000e+00, 1.24813681e+00,\n",
       "        1.24000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.70731995e+03, 1.36393005e+03, 1.80987339e+03,\n",
       "        2.38913989e+03, 2.44571951e+03, 2.06196134e+03, 1.73195996e+03,\n",
       "        1.53806447e+03, 1.46447474e+03, 1.41639001e+03, 1.37801018e+03,\n",
       "        1.34933523e+03, 1.33036516e+03, 1.32109998e+03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model does not seem to contain 4D layer. Grad CAM cannot be applied.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26092/363854424.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\benma\\anaconda3\\lib\\site-packages\\tf_explain\\core\\grad_cam.py\u001b[0m in \u001b[0;36mexplain\u001b[1;34m(self, validation_data, model, class_index, layer_name, use_guided_grads, colormap, image_weight)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mlayer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_grad_cam_target_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         outputs, grads = GradCAM.get_gradients_and_filters(\n",
      "\u001b[1;32mc:\\Users\\benma\\anaconda3\\lib\\site-packages\\tf_explain\\core\\grad_cam.py\u001b[0m in \u001b[0;36minfer_grad_cam_target_layer\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;34m\"Model does not seem to contain 4D layer. Grad CAM cannot be applied.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Model does not seem to contain 4D layer. Grad CAM cannot be applied."
     ]
    }
   ],
   "source": [
    "explainer = GradCAM()\n",
    "grid = explainer.explain(([x_test[0]], None), model, class_index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0da8f5b93ec0612bb8aed25290fce040bcd4618fccb82f778dd001cba2969b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
