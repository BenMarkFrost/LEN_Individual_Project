{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis code is adapted from:\\nhttps://www.youtube.com/watch?v=PCgrgHgy26c&t=1567s\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code is adapted from:\n",
    "https://www.youtube.com/watch?v=PCgrgHgy26c&t=1567s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from torch_explain.models.explainer import Explainer\n",
    "from torch_explain.logic.metrics import formula_consistency\n",
    "from torchmetrics.functional import accuracy\n",
    "# from load_datasets import load_mimic\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from torch.nn.functional import one_hot\n",
    "from func_timeout import func_set_timeout, func_timeout, FunctionTimedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features):\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "def __len__(self):\n",
    "    return len(self.features)\n",
    "\n",
    "def __getitem__(self, idx):\n",
    "    feature, label = self.features[idx]\n",
    "    return dict(\n",
    "        feature=torch.Tensor(feature.to_numpy()),\n",
    "        label=torch.Tensor(label).long()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_sequences, test_sequences, batch_size):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = PatientDataset(self.train_sequences)\n",
    "        self.test_dataset = PatientDataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False,\n",
    "            num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False,\n",
    "            num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benma\\AppData\\Local\\Temp/ipykernel_25208/3530429520.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_bundle = np.array(list(zip(x_train, y_train)))\n",
      "C:\\Users\\benma\\AppData\\Local\\Temp/ipykernel_25208/3530429520.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_bundle = np.array(list(zip(x_test, y_test)))\n"
     ]
    }
   ],
   "source": [
    "epochs=200\n",
    "batch_size=32\n",
    "\n",
    "df = pd.read_csv(\"cleanedTemporalData.csv\").set_index('PatientID')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for id, group in df.groupby('PatientID'):\n",
    "    tempGroup = group.reset_index()\n",
    "    \n",
    "    tempGroup = tempGroup.drop(['PatientID', 'Mortality14Days'], axis=1)\n",
    "\n",
    "    X.append(tempGroup.T.values)\n",
    "    y.append(group['Mortality14Days'].values[0])\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# print(X[0])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_bundle = np.array(list(zip(x_train, y_train)))\n",
    "\n",
    "test_bundle = np.array(list(zip(x_test, y_test)))\n",
    "\n",
    "# display(train_bundle[0])\n",
    "\n",
    "dataModule = PatientDataModule(train_bundle, test_bundle, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, n_classes, n_hidden=256, n_layers=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features, \n",
    "            hidden_size=n_hidden, \n",
    "            num_layers=n_layers, \n",
    "            batch_first=True,\n",
    "            dropout=0.75)\n",
    "\n",
    "        self.classifier = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "        x, (hidden, _) = self.lstm(x)\n",
    "\n",
    "        out = hidden[-1]\n",
    "\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientPredictor(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = PatientModel(n_features, n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features = batch['feature']\n",
    "        labels = batch['label']\n",
    "        loss, outputs = self.forward(features, labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = accuracy(predictions, labels)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        return {'loss': loss, 'accuracy': step_accuracy}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        features = batch['feature']\n",
    "        labels = batch['label']\n",
    "        loss, outputs = self.forward(features, labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = accuracy(predictions, labels)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        return {'loss': loss, 'accuracy': step_accuracy}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features = batch['feature']\n",
    "        labels = batch['label']\n",
    "        loss, outputs = self.forward(features, labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = accuracy(predictions, labels)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"test_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        return {'loss': loss, 'accuracy': step_accuracy}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 12, 48)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PatientPredictor(n_features=x_train.shape[1], n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x000001DB400C0F10>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x000001DB400C0F10>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\", \n",
    "    filename=\"best\", \n",
    "    save_top_k=1, \n",
    "    verbose=True, \n",
    "    monitor=\"val_loss\", \n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"patient_model\")\n",
    "\n",
    "trainer = pl.Trainer(logger=logger, \n",
    "                    checkpoint_callback=checkpoint_callback,\n",
    "                     max_epochs=1, \n",
    "                     gpus=1\n",
    "                    #  progress_bar_refresh_rate=30\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: lightning_logs\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | PatientModel     | 1.3 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.319     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c23e4cc41e4879b8c4a8b8eb657797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, dataModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25972), started 0:00:22 ago. (Use '!kill 25972' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d11fcbdc753673dc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d11fcbdc753673dc\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0da8f5b93ec0612bb8aed25290fce040bcd4618fccb82f778dd001cba2969b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
