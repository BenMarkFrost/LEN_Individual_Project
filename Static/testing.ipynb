{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The model code from this file is adapted from the following:\\nhttps://github.com/pietrobarbiero/pytorch_explain/blob/master/experiments/elens/mnist.py\\n\\nCredit to Pietro Barbiero for the original code.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The model code from this file is adapted from the following:\n",
    "https://github.com/pietrobarbiero/pytorch_explain/blob/master/experiments/elens/mnist.py\n",
    "\n",
    "Credit to Pietro Barbiero for the original code.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from scipy.interpolate import interp1d\n",
    "from Categorization import Categorizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import copy\n",
    "from torch.nn.functional import one_hot\n",
    "import imblearn\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from collections import Counter\n",
    "from tslearn.clustering import TimeSeriesKMeans, silhouette_score\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from dask.dataframe import from_pandas\n",
    "from tsfresh.utilities.distribution import MultiprocessingDistributor\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import hashlib \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from importlib import reload\n",
    "from temporalHelper import TemporalHelper as TH\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "from torch_explain.models.explainer import Explainer\n",
    "import time\n",
    "from torchmetrics.functional import precision_recall\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.linear_model import LassoCV\n",
    "from torch_explain.logic.metrics import formula_consistency\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clusteredData.csv', 'expertLabelledData.csv', 'metricExtractedData.csv', 'staticData.csv']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"./categorisedData/\")\n",
    "\n",
    "\n",
    "datasets = {file : pd.read_csv(\"./categorisedData/\" + file).set_index('PatientID') for file in files}\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "print(files)\n",
    "\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training clusteredData.csv\n",
      "\n",
      "Training on 2 classes\n",
      "Num concepts: 120\n",
      "Num classes: 2\n",
      "Split [1/10]\n",
      "690/173/96\n",
      "[(0, 666), (1, 24)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 666), (1, 666)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.96875, 'test_acc_epoch': 0.96875}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 34.5348334312439\n",
      "Number of features that impact on target 0: 12\n",
      "Explanation for target 0: ~CVP_StdDev_high\n",
      "Explanation accuracy: 0.6444444444444445\n",
      "Number of features that impact on target 1: 6\n",
      "Explanation for target 1: ~SVRI_StdDev_medium & ~SVRI_Mean_high & ~SVRI_Mean_medium & ~SVRI_Mean_very_high & ~SVRI_Mean_very_low\n",
      "Explanation accuracy: 0.49206349206349204\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9688), tensor(0.9688))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [2/10]\n",
      "690/173/96\n",
      "[(0, 663), (1, 27)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 663), (1, 663)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9583333134651184, 'test_acc_epoch': 0.9583333134651184}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 20.33842635154724\n",
      "Number of features that impact on target 0: 8\n",
      "Explanation for target 0: Arterial PaCO2_StdDev_low | Hemoglobin_StdDev_very_low | ~Hemoglobin_StdDev_very_low\n",
      "Explanation accuracy: 0.49206349206349204\n",
      "Number of features that impact on target 1: 10\n",
      "Explanation for target 1: ~Arterial BP [Diastolic]_StdDev_medium & ~Ionized Calcium_StdDev_low\n",
      "Explanation accuracy: 0.36374269005847953\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9583), tensor(0.9583))\n",
      "Split [3/10]\n",
      "690/173/96\n",
      "[(0, 669), (1, 21)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 669), (1, 669)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.96875, 'test_acc_epoch': 0.96875}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 9.75868558883667\n",
      "Number of features that impact on target 0: 6\n",
      "Explanation for target 0: Arterial BP [Diastolic]_StdDev_low | Arterial BP [Diastolic]_Mean_medium | Arterial BP [Diastolic]_Mean_very_low | SVR_StdDev_low | ~Arterial BP [Diastolic]_StdDev_very_high\n",
      "Explanation accuracy: 0.48663101604278075\n",
      "Number of features that impact on target 1: 7\n",
      "Explanation for target 1: ~Arterial BP Mean_StdDev_medium & ~Arterial PaCO2_StdDev_medium & ~Arterial pH_StdDev_very_low & ~Ionized Calcium_Mean_high & ~Platelets_Mean_low & ~SVRI_Mean_low\n",
      "Explanation accuracy: 0.5805042016806723\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9688), tensor(0.9688))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [4/10]\n",
      "690/173/96\n",
      "[(0, 662), (1, 28)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 662), (1, 662)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9270833134651184, 'test_acc_epoch': 0.9270833134651184}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 17.53336501121521\n",
      "Number of features that impact on target 0: 5\n",
      "Explanation for target 0: Arterial BP [Diastolic]_StdDev_low | Ionized Calcium_StdDev_low | ~Arterial BP [Diastolic]_StdDev_low\n",
      "Explanation accuracy: 0.49206349206349204\n",
      "Number of features that impact on target 1: 11\n",
      "Explanation for target 1: ~Arterial BP Mean_Mean_medium & ~Arterial BP [Diastolic]_StdDev_very_high & ~Arterial pH_StdDev_medium & ~Arterial pH_Mean_very_high & ~Platelets_Mean_high\n",
      "Explanation accuracy: 0.40372670807453426\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9271), tensor(0.9271))\n",
      "Split [5/10]\n",
      "690/173/96\n",
      "[(0, 661), (1, 29)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 661), (1, 661)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9375, 'test_acc_epoch': 0.9375}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 10.315515995025635\n",
      "Number of features that impact on target 0: 5\n",
      "Explanation for target 0: Arterial PaCO2_StdDev_medium | Arterial PaCO2_Mean_medium | ~Platelets_Mean_medium\n",
      "Explanation accuracy: 0.46067415730337086\n",
      "Number of features that impact on target 1: 3\n",
      "Explanation for target 1: CVP_Mean_very_high & ~Arterial pH_StdDev_very_low & ~Ionized Calcium_Mean_high\n",
      "Explanation accuracy: 0.47540983606557374\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9375), tensor(0.9375))\n",
      "Split [6/10]\n",
      "690/173/96\n",
      "[(0, 664), (1, 26)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 664), (1, 664)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9583333134651184, 'test_acc_epoch': 0.9583333134651184}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 152.74969744682312\n",
      "Number of features that impact on target 0: 18\n",
      "Explanation for target 0: Arterial BP [Systolic]_Mean_low | Arterial PaCO2_StdDev_high | CVP_Mean_very_low | Platelets_StdDev_low | Platelets_Mean_medium\n",
      "Explanation accuracy: 0.46368715083798884\n",
      "Number of features that impact on target 1: 4\n",
      "Explanation for target 1: None\n",
      "Explanation accuracy: 0\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9583), tensor(0.9583))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [7/10]\n",
      "690/173/96\n",
      "[(0, 666), (1, 24)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 666), (1, 666)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9479166865348816, 'test_acc_epoch': 0.9479166865348816}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 13.906607866287231\n",
      "Number of features that impact on target 0: 6\n",
      "Explanation for target 0: Arterial BP [Diastolic]_StdDev_medium | Ionized Calcium_StdDev_low | SVR_Mean_low | ~SVRI_StdDev_medium\n",
      "Explanation accuracy: 0.6293436293436294\n",
      "Number of features that impact on target 1: 7\n",
      "Explanation for target 1: ~SVRI_StdDev_very_high & ~SVRI_Mean_medium & ~SVRI_Mean_very_low\n",
      "Explanation accuracy: 0.4262639315134873\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9479), tensor(0.9479))\n",
      "Split [8/10]\n",
      "690/173/96\n",
      "[(0, 665), (1, 25)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 665), (1, 665)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9583333134651184, 'test_acc_epoch': 0.9583333134651184}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining time: 25.907658576965332\n",
      "Number of features that impact on target 0: 4\n",
      "Explanation for target 0: Arterial BP [Diastolic]_StdDev_medium | ~SVR_StdDev_very_high\n",
      "Explanation accuracy: 0.4838709677419355\n",
      "Number of features that impact on target 1: 14\n",
      "Explanation for target 1: ~Arterial BP Mean_StdDev_medium & ~Arterial BP Mean_Mean_medium & ~Arterial BP [Diastolic]_StdDev_very_low & ~Arterial PaCO2_StdDev_medium & ~Arterial PaCO2_Mean_low & ~Arterial pH_StdDev_very_low & ~CVP_StdDev_very_low & ~Hemoglobin_StdDev_low & ~Ionized Calcium_Mean_high & ~Platelets_StdDev_medium & ~SVRI_StdDev_medium\n",
      "Explanation accuracy: 0.4866310160427807\n",
      "Type: <class 'torch.Tensor'>\n",
      "(tensor(0.9583), tensor(0.9583))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [9/10]\n",
      "690/173/96\n",
      "[(0, 669), (1, 21)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 4.9 K \n",
      "-------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 669), (1, 669)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9583333134651184, 'test_acc_epoch': 0.9583333134651184}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for file in files[:1]:\n",
    "\n",
    "    print(f\"Training {file}\\n\")\n",
    "\n",
    "    data = datasets[file]\n",
    "\n",
    "    if file == \"staticData.csv\":\n",
    "        targetName = \"deathperiod\"\n",
    "    else:\n",
    "        targetName = \"Mortality14Days\"\n",
    "\n",
    "    targetSeries = data[targetName]\n",
    "    data = data.drop(columns=[targetName])\n",
    "\n",
    "\n",
    "    dataTensor = torch.FloatTensor(data.to_numpy())\n",
    "    targetTensor = one_hot(torch.tensor(targetSeries.values).to(torch.long)).to(torch.float)\n",
    "\n",
    "\n",
    "    dataset = TensorDataset(dataTensor, targetTensor)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "\n",
    "    val_size = (len(dataset) - train_size) // 2\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=train_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=test_size)\n",
    "\n",
    "\n",
    "\n",
    "    n_concepts = next(iter(train_loader))[0].shape[1]\n",
    "    # self.n_concepts = n_concepts\n",
    "\n",
    "\n",
    "    n_classes = targetTensor.shape[1]\n",
    "    # self.n_classes = n_classes\n",
    "\n",
    "    print(\"Training on {} classes\".format(n_classes))\n",
    "\n",
    "    print(\"Num concepts: {}\".format(n_concepts))\n",
    "    print(\"Num classes: {}\".format(n_classes))\n",
    "\n",
    "    base_dir = f'./results/mimicLEN/explainer'\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    seed_everything(40)\n",
    "\n",
    "    n_splits = 10\n",
    "\n",
    "    # self.n_splits = n_splits\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # self.skf = skf\n",
    "\n",
    "    results_list = []\n",
    "    feature_selection = []\n",
    "    explanations = {i: [] for i in range(n_classes)}\n",
    "\n",
    "    explanations_list = []\n",
    "    scores_list = []\n",
    "\n",
    "    x = dataTensor\n",
    "    y = targetTensor\n",
    "\n",
    "\n",
    "    for split, (trainval_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(),\n",
    "                                                            y.argmax(dim=1).cpu().detach().numpy())):\n",
    "        \n",
    "        # print(x)\n",
    "\n",
    "        # x = x.cpu()\n",
    "\n",
    "        # print(x)\n",
    "        # x = x.to(torch.device(\"cpu\"))\n",
    "        # y = y.float()\n",
    "        # y = y.to(torch.device(\"cpu\"))\n",
    "        # y = one_hot(y.to(torch.int64)).to(torch.float)\n",
    "\n",
    "        # print(x.shape)\n",
    "        # print(y, y.shape)\n",
    "\n",
    "\n",
    "        print(f'Split [{split + 1}/{n_splits}]')\n",
    "        x_trainval, x_test = torch.FloatTensor(x[trainval_index]), torch.FloatTensor(x[test_index])\n",
    "        y_trainval, y_test = torch.FloatTensor(y[trainval_index]), torch.FloatTensor(y[test_index])\n",
    "        x_train_unbalanced, x_val, y_train_unbalanced, y_val = train_test_split(x_trainval, y_trainval, test_size=0.2, random_state=42)\n",
    "        print(f'{len(y_train_unbalanced)}/{len(y_val)}/{len(y_test)}')\n",
    "\n",
    "\n",
    "        # Rebalancing training set\n",
    "        obj = imblearn.over_sampling.SMOTEN(random_state=0, n_jobs=4)\n",
    "\n",
    "        print(sorted(Counter(torch.argmax(y_train_unbalanced, axis=1).numpy()).items()))\n",
    "\n",
    "        x_train, y_train = obj.fit_resample(x_train_unbalanced.numpy(), torch.argmax(y_train_unbalanced, axis=1).numpy())\n",
    "\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "\n",
    "        y_train = one_hot(torch.tensor(y_train).to(torch.long)).to(torch.float)\n",
    "        x_train = torch.FloatTensor(x_train)\n",
    "\n",
    "        train_data = TensorDataset(x_train, y_train)\n",
    "        val_data = TensorDataset(x_val, y_val)\n",
    "        test_data = TensorDataset(x_test, y_test)\n",
    "        train_loader = DataLoader(train_data, batch_size=train_size)\n",
    "        val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "        test_loader = DataLoader(test_data, batch_size=test_size)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(dirpath=base_dir, monitor='val_loss', save_top_k=1)\n",
    "\n",
    "        # Constructs the way that the model will be trained\n",
    "        trainer = Trainer(max_epochs=200, gpus=1, auto_lr_find=True, deterministic=True,\n",
    "                        check_val_every_n_epoch=1, default_root_dir=base_dir,\n",
    "                        weights_save_path=base_dir, callbacks=[checkpoint_callback], enable_progress_bar=False)\n",
    "\n",
    "        # This is the model itself, which is extended from pytorch_lightning\n",
    "        model = Explainer(n_concepts=n_concepts, n_classes=n_classes, l1=1e-3, lr=0.01,\n",
    "                        explainer_hidden=[20], temperature=0.7)\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        # print(f\"Gamma: {model.model[0].concept_mask}\")\n",
    "        model.freeze()\n",
    "        print(\"\\nTesting...\\n\")\n",
    "        model_results = trainer.test(model, test_dataloaders=test_loader)\n",
    "        print(\"\\nExplaining\\n\")\n",
    "        results, f = model.explain_class(val_dataloaders=val_loader, train_dataloaders=train_loader, test_dataloaders=test_loader,\n",
    "                                        topk_explanations=10,\n",
    "                                        concept_names=data.columns)\n",
    "        end = time.time()\n",
    "        explanations_list.append(f)\n",
    "\n",
    "        print(f\"Explaining time: {end - start}\")\n",
    "        results['model_accuracy'] = model_results[0]['test_acc']\n",
    "        results['extraction_time'] = end\n",
    "\n",
    "        results_list.append(results)\n",
    "        extracted_concepts = []\n",
    "        all_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "        common_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "        for j in range(n_classes):\n",
    "            # print(f[j]['explanation'])\n",
    "            n_used_concepts = sum(model.model[0].concept_mask[j] > 0.5)\n",
    "            print(f\"Number of features that impact on target {j}: {n_used_concepts}\")\n",
    "            print(f\"Explanation for target {j}: {f[j]['explanation']}\")\n",
    "            print(f\"Explanation accuracy: {f[j]['explanation_accuracy']}\")\n",
    "            explanations[j].append(f[j]['explanation'])\n",
    "            extracted_concepts.append(n_used_concepts)\n",
    "            all_concepts += model.model[0].concept_mask[j] > 0.5\n",
    "            common_concepts *= model.model[0].concept_mask[j] > 0.5\n",
    "\n",
    "        results['extracted_concepts'] = np.mean(extracted_concepts)\n",
    "        results['common_concepts_ratio'] = sum(common_concepts) / sum(all_concepts)\n",
    "\n",
    "        # Precision, Recall, F1\n",
    "        # print(x_test)\n",
    "        print(\"Type:\", type(x_test))\n",
    "        y_pred = torch.argmax(model(x_test), axis=1)\n",
    "        # print(\"Predictions:\", y_pred)\n",
    "        y_test_argmax = torch.argmax(y_test, axis=1)\n",
    "        # print(\"Actual:\", y_test_argmax)\n",
    "\n",
    "        scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy()), recall_score(y_test_argmax.numpy(), y_pred.numpy()), precision_score(y_test_argmax.numpy(), y_pred.numpy())]\n",
    "\n",
    "        print(f\"{file} split {split+1} scores: {scores}\")\n",
    "\n",
    "        scores_list.append(scores)\n",
    "\n",
    "\n",
    "        prec_rec = precision_recall(y_pred, y_test_argmax, num_classes = n_classes)\n",
    "\n",
    "        print(prec_rec)\n",
    "\n",
    "        # compare against standard feature selection\n",
    "        i_mutual_info = mutual_info_classif(x_trainval, y_trainval[:, 1])\n",
    "        i_chi2 = chi2(x_trainval, y_trainval[:, 1])[0]\n",
    "        i_chi2[np.isnan(i_chi2)] = 0\n",
    "        lasso = LassoCV(cv=5, random_state=0).fit(x_trainval, y_trainval[:, 1])\n",
    "        i_lasso = np.abs(lasso.coef_)\n",
    "        i_mu = model.model[0].concept_mask[1]\n",
    "        # print(model.model[0].concept_mask)\n",
    "        df = pd.DataFrame(np.hstack([\n",
    "            i_mu.numpy(),\n",
    "            # i_mutual_info / np.max(i_mutual_info),\n",
    "            # i_chi2 / np.max(i_chi2),\n",
    "            # i_lasso / np.max(i_lasso),\n",
    "        ]).T, columns=['feature importance'])\n",
    "        df['method'] = 'explainer'\n",
    "        # df.iloc[90:, 1] = 'MI'\n",
    "        # df.iloc[180:, 1] = 'CHI2'\n",
    "        # df.iloc[270:, 1] = 'Lasso'\n",
    "        df['feature'] = np.hstack([np.arange(0, n_concepts)])\n",
    "        feature_selection.append(df)\n",
    "\n",
    "\n",
    "    results_dict[file] = [results_list, explanations_list, scores_list]\n",
    "\n",
    "\n",
    "# self.feature_selection = feature_selection\n",
    "# # print(self.feature_selection)\n",
    "\n",
    "# self.df = df\n",
    "# self.explanations = explanations\n",
    "# self.results_list = results_list\n",
    "# print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusteredData.csv\n",
      "['dataset', 'explanation_accuracy_split_0', 'explanation_fidelity_split_0', 'explanation_complexity_split_0', 'model_accuracy_split_0', 'extraction_time_split_0', 'extracted_concepts_split_0', 'common_concepts_ratio_split_0', 'target_class_split_0', 'explanation_split_0', 'explanation_accuracy_split_0', 'explanation_fidelity_split_0', 'explanation_complexity_split_0', 'target_class_split_0', 'explanation_split_0', 'explanation_accuracy_split_0', 'explanation_fidelity_split_0', 'explanation_complexity_split_0']\n",
      "['dataset', 'explanation_accuracy_split_0', 'explanation_fidelity_split_0', 'explanation_complexity_split_0', 'model_accuracy_split_0', 'extraction_time_split_0', 'extracted_concepts_split_0', 'common_concepts_ratio_split_0', 'target_class_split_0', 'explanation_split_0', 'explanation_accuracy_split_0', 'explanation_fidelity_split_0', 'explanation_complexity_split_0', 'target_class_split_0', 'explanation_split_0', 'explanation_accuracy_split_0', 'explanation_fidelity_split_0', 'explanation_complexity_split_0', 'explanation_accuracy_split_1', 'explanation_fidelity_split_1', 'explanation_complexity_split_1', 'model_accuracy_split_1', 'extraction_time_split_1', 'extracted_concepts_split_1', 'common_concepts_ratio_split_1', 'target_class_split_1', 'explanation_split_1', 'explanation_accuracy_split_1', 'explanation_fidelity_split_1', 'explanation_complexity_split_1', 'target_class_split_1', 'explanation_split_1', 'explanation_accuracy_split_1', 'explanation_fidelity_split_1', 'explanation_complexity_split_1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>explanation_accuracy_split_0</th>\n",
       "      <th>explanation_fidelity_split_0</th>\n",
       "      <th>explanation_complexity_split_0</th>\n",
       "      <th>model_accuracy_split_0</th>\n",
       "      <th>extraction_time_split_0</th>\n",
       "      <th>extracted_concepts_split_0</th>\n",
       "      <th>common_concepts_ratio_split_0</th>\n",
       "      <th>target_class_split_0</th>\n",
       "      <th>explanation_split_0</th>\n",
       "      <th>...</th>\n",
       "      <th>target_class_split_1</th>\n",
       "      <th>explanation_split_1</th>\n",
       "      <th>explanation_accuracy_split_1</th>\n",
       "      <th>explanation_fidelity_split_1</th>\n",
       "      <th>explanation_complexity_split_1</th>\n",
       "      <th>target_class_split_1</th>\n",
       "      <th>explanation_split_1</th>\n",
       "      <th>explanation_accuracy_split_1</th>\n",
       "      <th>explanation_fidelity_split_1</th>\n",
       "      <th>explanation_complexity_split_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staticData.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.757887</td>\n",
       "      <td>1.657886e+09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>tensor(0.2222)</td>\n",
       "      <td>0</td>\n",
       "      <td>CVP__quantile__q_0.3_high | CVP__c3__lag_2_low...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clusteredData.csv</td>\n",
       "      <td>0.485373</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>1.657886e+09</td>\n",
       "      <td>15.5</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Arterial BP Mean_Mean_medium | Arterial BP [Di...</td>\n",
       "      <td>0.482472</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Arterial PaCO2_StdDev_low &amp; Arterial pH_StdDev...</td>\n",
       "      <td>0.488273</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expertLabelledData.csv</td>\n",
       "      <td>0.502413</td>\n",
       "      <td>0.857016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.925400</td>\n",
       "      <td>1.657886e+09</td>\n",
       "      <td>18.5</td>\n",
       "      <td>tensor(0.1562)</td>\n",
       "      <td>0</td>\n",
       "      <td>~CVP_Mean_very_high</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Arterial_pH_Min_very_low | Heart_Rate_Min_high...</td>\n",
       "      <td>0.480812</td>\n",
       "      <td>0.813499</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>CVP_Min_medium &amp; ~Potassium_Min_medium</td>\n",
       "      <td>0.524015</td>\n",
       "      <td>0.900533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>metricExtractedData.csv</td>\n",
       "      <td>0.563349</td>\n",
       "      <td>0.939583</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.657886e+09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>tensor(0.2222)</td>\n",
       "      <td>0</td>\n",
       "      <td>Arterial_pH_Max_low | CVP_Max_very_low | NBP_S...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CVP__root_mean_square_high | CVP__c3__lag_3_lo...</td>\n",
       "      <td>0.559599</td>\n",
       "      <td>0.920833</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>~CVP__mean_high &amp; ~CVP__c3__lag_3_low &amp; ~CVP__...</td>\n",
       "      <td>0.567100</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset  explanation_accuracy_split_0  \\\n",
       "0           staticData.csv                      0.000000   \n",
       "1        clusteredData.csv                      0.485373   \n",
       "2   expertLabelledData.csv                      0.502413   \n",
       "3  metricExtractedData.csv                      0.563349   \n",
       "\n",
       "   explanation_fidelity_split_0  explanation_complexity_split_0  \\\n",
       "0                      0.000000                             0.0   \n",
       "1                      0.878125                             4.5   \n",
       "2                      0.857016                             2.5   \n",
       "3                      0.939583                             4.5   \n",
       "\n",
       "   model_accuracy_split_0  extraction_time_split_0  \\\n",
       "0                0.757887             1.657886e+09   \n",
       "1                0.956250             1.657886e+09   \n",
       "2                0.925400             1.657886e+09   \n",
       "3                0.958333             1.657886e+09   \n",
       "\n",
       "   extracted_concepts_split_0 common_concepts_ratio_split_0  \\\n",
       "0                        11.0                tensor(0.2222)   \n",
       "1                        15.5                    tensor(0.)   \n",
       "2                        18.5                tensor(0.1562)   \n",
       "3                        11.0                tensor(0.2222)   \n",
       "\n",
       "   target_class_split_0                                explanation_split_0  \\\n",
       "0                     0  CVP__quantile__q_0.3_high | CVP__c3__lag_2_low...   \n",
       "1                     0                                               None   \n",
       "2                     0                                ~CVP_Mean_very_high   \n",
       "3                     0  Arterial_pH_Max_low | CVP_Max_very_low | NBP_S...   \n",
       "\n",
       "   ...  target_class_split_1  \\\n",
       "0  ...                     0   \n",
       "1  ...                     0   \n",
       "2  ...                     0   \n",
       "3  ...                     0   \n",
       "\n",
       "                                 explanation_split_1  \\\n",
       "0                                               None   \n",
       "1  Arterial BP Mean_Mean_medium | Arterial BP [Di...   \n",
       "2  Arterial_pH_Min_very_low | Heart_Rate_Min_high...   \n",
       "3  CVP__root_mean_square_high | CVP__c3__lag_3_lo...   \n",
       "\n",
       "   explanation_accuracy_split_1  explanation_fidelity_split_1  \\\n",
       "0                      0.000000                      0.000000   \n",
       "1                      0.482472                      0.775000   \n",
       "2                      0.480812                      0.813499   \n",
       "3                      0.559599                      0.920833   \n",
       "\n",
       "   explanation_complexity_split_1  target_class_split_1  \\\n",
       "0                               0                     1   \n",
       "1                               4                     1   \n",
       "2                               3                     1   \n",
       "3                               5                     1   \n",
       "\n",
       "                                 explanation_split_1  \\\n",
       "0                                               None   \n",
       "1  Arterial PaCO2_StdDev_low & Arterial pH_StdDev...   \n",
       "2             CVP_Min_medium & ~Potassium_Min_medium   \n",
       "3  ~CVP__mean_high & ~CVP__c3__lag_3_low & ~CVP__...   \n",
       "\n",
       "   explanation_accuracy_split_1  explanation_fidelity_split_1  \\\n",
       "0                      0.000000                      0.000000   \n",
       "1                      0.488273                      0.981250   \n",
       "2                      0.524015                      0.900533   \n",
       "3                      0.567100                      0.958333   \n",
       "\n",
       "   explanation_complexity_split_1  \n",
       "0                               0  \n",
       "1                               5  \n",
       "2                               2  \n",
       "3                               4  \n",
       "\n",
       "[4 rows x 35 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = []\n",
    "\n",
    "columns.append(\"dataset\")\n",
    "\n",
    "x = files[0]\n",
    "\n",
    "print(x)\n",
    "\n",
    "for n in range(n_splits):\n",
    "    # print(x,n)\n",
    "    columns.extend([str(j + \"_split_\" + str(n)) for j in results_dict[x][0][n]])\n",
    "    \n",
    "\n",
    "        \n",
    "    for k in range(len(results_dict[x][1][n])):\n",
    "        columns.extend([str(j + \"_split_\" + str(n)) for j in results_dict[x][1][n][k]])\n",
    "\n",
    "    print(columns)\n",
    "\n",
    "\n",
    "# print(columns)\n",
    "\n",
    "data = []\n",
    "\n",
    "for x in results_dict:\n",
    "    row = []\n",
    "    row.append(x)\n",
    "    for n in range(n_splits):\n",
    "        # print(x,n)\n",
    "        row.extend(results_dict[x][0][n].values())\n",
    "        \n",
    "        # print(columns)\n",
    "                \n",
    "        for k in range(len(results_dict[x][1][n])):\n",
    "            row.extend(results_dict[x][1][n][k].values())\n",
    "\n",
    "    data.append(row)\n",
    "\n",
    "\n",
    "resultsDF = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "resultsDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['CVP__root_mean_square_high | CVP__c3__lag_3_low | CVP__c3__lag_3_very_low | (CVP__mean_very_low & ~CVP__minimum_very_low)', 'CVP__quantile__q_0.3_high | CVP__c3__lag_2_low | ~CVP__quantile__q_0.1_low'], 1: ['~CVP__mean_high & ~CVP__c3__lag_3_low & ~CVP__c3__lag_3_very_low & ~CVP__c3__lag_1_low', 'CVP__quantile__q_0.1_low & CVP__quantile__q_0.7_very_high & ~CVP__minimum_very_low']}\n",
      "['CVP__root_mean_square_high | CVP__c3__lag_3_low | CVP__c3__lag_3_very_low | (CVP__mean_very_low & ~CVP__minimum_very_low)', 'CVP__quantile__q_0.3_high | CVP__c3__lag_2_low | ~CVP__quantile__q_0.1_low']\n",
      "['~CVP__mean_high & ~CVP__c3__lag_3_low & ~CVP__c3__lag_3_very_low & ~CVP__c3__lag_1_low', 'CVP__quantile__q_0.1_low & CVP__quantile__q_0.7_very_high & ~CVP__minimum_very_low']\n",
      "Feature selection:      feature importance     method  feature\n",
      "0                False  explainer        0\n",
      "1                False  explainer        1\n",
      "2                False  explainer        2\n",
      "3                False  explainer        3\n",
      "4                False  explainer        4\n",
      "..                 ...        ...      ...\n",
      "65               False  explainer       65\n",
      "66               False  explainer       66\n",
      "67               False  explainer       67\n",
      "68                True  explainer       68\n",
      "69               False  explainer       69\n",
      "\n",
      "[140 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/2]\n",
      "Split [2/2]\n",
      "Random forest scores: 0.9405641092553931 (+/- 0.0009807759220598622)\n",
      "Decision tree scores: 0.9572459986082116 (+/- 0.0010873347251217913)\n",
      "Mu net scores (model): 0.9405445158481598 (+/- 0.02515715884821307)\n",
      "Mu net scores (exp): 0.5207440200706117 (+/- 0.060253194407512575)\n"
     ]
    }
   ],
   "source": [
    "base_dir = f'./results/mimicLEN/explainer'\n",
    "\n",
    "consistencies = []\n",
    "print(explanations)\n",
    "for j in range(n_classes):\n",
    "    if explanations[j][0] is None:\n",
    "        continue\n",
    "    consistencies.append(formula_consistency(explanations[j]))\n",
    "explanation_consistency = np.mean(consistencies)\n",
    "\n",
    "feature_selection = pd.concat(feature_selection, axis=0)\n",
    "\n",
    "print(\"Feature selection: \", feature_selection)\n",
    "\n",
    "f1 = feature_selection[feature_selection['feature'] <= n_concepts//3]\n",
    "f2 = feature_selection[(feature_selection['feature'] > n_concepts//3) & (feature_selection['feature'] <= (n_concepts*2)//3)]\n",
    "f3 = feature_selection[feature_selection['feature'] > (n_concepts*2)//3]\n",
    "\n",
    "plt.figure(figsize=[10, 10])\n",
    "plt.subplot(1, 3, 1)\n",
    "ax = sns.barplot(y=f1['feature'], x=f1.iloc[:, 0],\n",
    "                hue=f1['method'], orient='h', errwidth=0.5, errcolor='k')\n",
    "ax.get_legend().remove()\n",
    "plt.subplot(1, 3, 2)\n",
    "ax = sns.barplot(y=f2['feature'], x=f2.iloc[:, 0],\n",
    "                hue=f2['method'], orient='h', errwidth=0.5, errcolor='k')\n",
    "plt.xlabel('')\n",
    "ax.get_legend().remove()\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(y=f3['feature'], x=f3.iloc[:, 0],\n",
    "            hue=f3['method'], orient='h', errwidth=0.5, errcolor='k')\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(base_dir, 'barplot_mimic.png'))\n",
    "plt.savefig(os.path.join(base_dir, 'barplot_mimic.pdf'))\n",
    "plt.show()\n",
    "\n",
    "# print(feature_selection.iloc[:, 1], feature_selection.iloc[:, 0])\n",
    "\n",
    "# plt.figure(figsize=[6, 4])\n",
    "# sns.boxplot(x=feature_selection.iloc[:, 1], y=feature_selection.iloc[:, 0])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(base_dir, 'boxplot_mimic.png'))\n",
    "# plt.savefig(os.path.join(base_dir, 'boxplot_mimic.pdf'))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df['explanation_consistency'] = explanation_consistency\n",
    "results_df.to_csv(os.path.join(base_dir, 'results_aware_mimic.csv'))\n",
    "results_df\n",
    "\n",
    "\n",
    "results_df.mean()\n",
    "\n",
    "results_df.sem()\n",
    "\n",
    "x = dataTensor\n",
    "y = targetTensor\n",
    "\n",
    "dt_scores, rf_scores = [], []\n",
    "for split, (trainval_index, test_index) in enumerate(\n",
    "        skf.split(x.cpu().detach().numpy(), y.argmax(dim=1).cpu().detach().numpy())):\n",
    "    print(f'Split [{split + 1}/{n_splits}]')\n",
    "    x_trainval, x_test = x[trainval_index], x[test_index]\n",
    "    y_trainval, y_test = y[trainval_index].argmax(dim=1), y[test_index].argmax(dim=1)\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(max_depth=5, random_state=split)\n",
    "    dt_model.fit(x_trainval, y_trainval)\n",
    "    dt_scores.append(dt_model.score(x_test, y_test))\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state=split)\n",
    "    rf_model.fit(x_trainval, y_trainval)\n",
    "    rf_scores.append(rf_model.score(x_test, y_test))\n",
    "\n",
    "print(f'Random forest scores: {np.mean(rf_scores)} (+/- {np.std(rf_scores)})')\n",
    "print(f'Decision tree scores: {np.mean(dt_scores)} (+/- {np.std(dt_scores)})')\n",
    "print(f'Mu net scores (model): {results_df[\"model_accuracy\"].mean()} (+/- {results_df[\"model_accuracy\"].std()})')\n",
    "print(\n",
    "    f'Mu net scores (exp): {results_df[\"explanation_accuracy\"].mean()} (+/- {results_df[\"explanation_accuracy\"].std()})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5766791432730298\n",
      "0.23529411764705882\n",
      "0.16\n"
     ]
    }
   ],
   "source": [
    "# Testing on non-rebalanced data\n",
    "\n",
    "print(f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'))\n",
    "print(recall_score(y_test_argmax.numpy(), y_pred.numpy()))\n",
    "print(precision_score(y_test_argmax.numpy(), y_pred.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97136564, 0.16      ]),\n",
       " array([0.95454545, 0.23529412]),\n",
       " array([0.9628821 , 0.19047619]),\n",
       " array([462,  17], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test_argmax.numpy(), y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority class correct: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Minority class correct: \" + str(torch.sum(torch.logical_and((y_pred == 1), (y_test_argmax == 1))).item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0da8f5b93ec0612bb8aed25290fce040bcd4618fccb82f778dd001cba2969b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
