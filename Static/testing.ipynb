{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The model code from this file is adapted from the following:\\nhttps://github.com/pietrobarbiero/pytorch_explain/blob/master/experiments/elens/mnist.py\\n\\nCredit to Pietro Barbiero for the original code.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The model code from this file is adapted from the following:\n",
    "https://github.com/pietrobarbiero/pytorch_explain/blob/master/experiments/elens/mnist.py\n",
    "\n",
    "Credit to Pietro Barbiero for the original code.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from scipy.interpolate import interp1d\n",
    "from Categorization import Categorizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import copy\n",
    "from torch.nn.functional import one_hot\n",
    "import imblearn\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from collections import Counter\n",
    "from tslearn.clustering import TimeSeriesKMeans, silhouette_score\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from dask.dataframe import from_pandas\n",
    "from tsfresh.utilities.distribution import MultiprocessingDistributor\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import hashlib \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from importlib import reload\n",
    "from temporalHelper import TemporalHelper as TH\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "from torch_explain.models.explainer import Explainer\n",
    "import time\n",
    "from torchmetrics.functional import precision_recall\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.linear_model import LassoCV\n",
    "from torch_explain.logic.metrics import formula_consistency\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "from func_timeout import func_set_timeout, func_timeout, FunctionTimedOut\n",
    "from datetime import date\n",
    "from pytorch_lightning.callbacks import ModelPruning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['categorisedData_featureSelected.csv', 'clusteredData.csv', 'expertLabelledData.csv', 'expertLabelledDataSimple.csv', 'expertLabelledDataSimple_featureSelected.csv', 'metricExtractedData.csv', 'staticData.csv', 'staticDataSimple.csv', 'staticDataSimple_featureSelected.csv', 'staticData_featureSelected.csv']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"./categorisedData/\")\n",
    "\n",
    "\n",
    "datasets = {file : pd.read_csv(\"./categorisedData/\" + file).set_index('PatientID') for file in files}\n",
    "\n",
    "\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expertLabelledDataSimple.csv']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(files[3:4])\n",
    "\n",
    "print(len(datasets))\n",
    "\n",
    "results_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_set_timeout(300)\n",
    "def explain_with_timeout(model, val_data, train_data, test_data, topk_expl, concepts):\n",
    "\n",
    "    return model.explain_class(val_dataloaders=val_data, train_dataloaders=train_data, test_dataloaders=test_data, topk_explanations=topk_expl, concept_names=concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training categorisedData_featureSelected.csv\n",
      "\n",
      "0    924\n",
      "1     35\n",
      "Name: Mortality14Days, dtype: int64\n",
      "Training on 2 classes\n",
      "Num concepts: 14\n",
      "Num classes: 2\n",
      "Split [1/5]\n",
      "[(0, 587), (1, 26)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:57: LightningDeprecationWarning: Setting `Trainer(weights_save_path=)` has been deprecated in v1.6 and will be removed in v1.8. Please pass ``dirpath`` directly to the `ModelCheckpoint` callback\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:611: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 2.3 K \n",
      "-------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 587), (1, 587)]\n",
      "0    924\n",
      "1     35\n",
      "Name: Mortality14Days, dtype: int64\n",
      "tensor([0.0011, 0.0286])\n",
      "Sizes:  (767, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1933: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "for file in files[:1]:\n",
    "\n",
    "    print(f\"Training {file}\\n\")\n",
    "\n",
    "    data = datasets[file]\n",
    "\n",
    "    if file in [\"staticData.csv\", \"staticDataSimple.csv\", \"staticData_featureSelected.csv\", \"staticDataSimple_featureSelected.csv\"]:\n",
    "        targetName = \"deathperiod\"\n",
    "    else:\n",
    "        targetName = \"Mortality14Days\"\n",
    "\n",
    "    targetSeries = data[targetName]\n",
    "    print(data[targetName].value_counts())\n",
    "    data = data.drop(columns=[targetName])\n",
    "\n",
    "    dataTensor = torch.FloatTensor(data.to_numpy())\n",
    "    targetTensor = one_hot(torch.tensor(targetSeries.values).to(torch.long)).to(torch.float)\n",
    "\n",
    "\n",
    "    dataset = TensorDataset(dataTensor, targetTensor)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "\n",
    "    val_size = (len(dataset) - train_size) // 2\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    # class_count = targetSeries.value_counts().values\n",
    "    # weights = 1 / torch.Tensor(class_count)\n",
    "\n",
    "    # sampler = WeightedRandomSampler(weights, train_size)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=train_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=test_size)\n",
    "\n",
    "\n",
    "\n",
    "    n_concepts = next(iter(train_loader))[0].shape[1]\n",
    "    # self.n_concepts = n_concepts\n",
    "\n",
    "\n",
    "    n_classes = targetTensor.shape[1]\n",
    "    # self.n_classes = n_classes\n",
    "\n",
    "    print(\"Training on {} classes\".format(n_classes))\n",
    "\n",
    "    print(\"Num concepts: {}\".format(n_concepts))\n",
    "    print(\"Num classes: {}\".format(n_classes))\n",
    "\n",
    "    base_dir = f'./results/mimicLEN/explainer'\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    seed_everything(40)\n",
    "\n",
    "    n_splits = 5\n",
    "\n",
    "    # self.n_splits = n_splits\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # self.skf = skf\n",
    "\n",
    "    results_list = []\n",
    "    feature_selection = []\n",
    "    explanations = {i: [] for i in range(n_classes)}\n",
    "\n",
    "    explanations_list = []\n",
    "    splitResults_list = []\n",
    "    scores_list = []\n",
    "\n",
    "    x = dataTensor\n",
    "    y = targetTensor\n",
    "\n",
    "\n",
    "    for split, (trainval_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(),\n",
    "                                                            y.argmax(dim=1).cpu().detach().numpy())):\n",
    "        \n",
    "\n",
    "        print(f'Split [{split + 1}/{n_splits}]')\n",
    "        x_trainval, x_test = torch.FloatTensor(x[trainval_index]), torch.FloatTensor(x[test_index])\n",
    "        y_trainval, y_test = torch.FloatTensor(y[trainval_index]), torch.FloatTensor(y[test_index])\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "        # Rebalancing training set\n",
    "        obj = imblearn.over_sampling.SMOTEN(random_state=0, n_jobs=4)\n",
    "\n",
    "        print(sorted(Counter(torch.argmax(y_train, axis=1).numpy()).items()))\n",
    "\n",
    "        x_train, y_train = obj.fit_resample(x_train.numpy(), torch.argmax(y_train, axis=1).numpy())\n",
    "\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "\n",
    "        class_count = pd.Series(targetSeries).value_counts()\n",
    "        print(class_count)\n",
    "        weights = 1. / torch.FloatTensor(class_count.values)\n",
    "\n",
    "        print(weights)\n",
    "        # print(y_train.numpy().astype(np.int64))\n",
    "\n",
    "        # print(weights)\n",
    "\n",
    "        # print(y_train_unbalanced.numpy().astype(np.int64))\n",
    "\n",
    "        # train_weights = np.array([weights[t] for t in torch.argmax(y_train, axis=1).numpy()]).astype(np.float64)\n",
    "\n",
    "        # test_weights = np.array([weights[t] for t in np.argmax(y_test.numpy(), axis=1).astype(np.int64)]).astype(np.float64)\n",
    "        \n",
    "        # val_weights = np.array([weights[t] for t in np.argmax(y_val.numpy(), axis=1).astype(np.int64)]).astype(np.float64)\n",
    "\n",
    "        # print(train_weights)\n",
    "\n",
    "        # print(train_weights)\n",
    "        # print(len(train_weights), len(y_train.numpy()))\n",
    "\n",
    "        # replacement=False\n",
    "\n",
    "        # train_sampler = WeightedRandomSampler(train_weights, len(y_train), replacement=True)\n",
    "\n",
    "        # test_sampler = WeightedRandomSampler(test_weights, len(y_test), replacement=True)\n",
    "\n",
    "        # val_sampler = WeightedRandomSampler(val_weights, len(y_val), replacement=True)\n",
    "\n",
    "\n",
    "        targetTensor = one_hot(torch.tensor(y_train).to(torch.long)).to(torch.float)\n",
    "        # targetTensor = y_train\n",
    "        x_train = torch.FloatTensor(x_train)\n",
    "\n",
    "        # print(targetTensor)\n",
    "\n",
    "        # y_val = one_hot(y_val.to(torch.long)).to(torch.float)\n",
    "\n",
    "        # y_test = one_hot(y_test.to(torch.long)).to(torch.float)\n",
    "\n",
    "\n",
    "\n",
    "        train_data = TensorDataset(x_train, targetTensor)\n",
    "        val_data = TensorDataset(x_val, y_val)\n",
    "        test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=train_size)\n",
    "        val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "        test_loader = DataLoader(test_data, batch_size=len(y_test.numpy()))\n",
    "\n",
    "        # y_ = pd.Series(np.argmax(next(iter(train_loader))[1].numpy(), axis=1)).value_counts()\n",
    "        # print(y_)\n",
    "\n",
    "        print(\"Sizes: \", (train_size, test_size, val_size))\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(dirpath=base_dir, monitor='val_loss', mode='min', save_top_k=1)\n",
    "\n",
    "        # Constructs the way that the model will be trained\n",
    "        logger = TensorBoardLogger(\"./runs/splits/\", name=file)\n",
    "\n",
    "        # Constructs the way that the model will be trained\n",
    "        trainer = Trainer(max_epochs=800, gpus=1, auto_lr_find=True, deterministic=True,\n",
    "                    check_val_every_n_epoch=1, default_root_dir=base_dir,\n",
    "                    weights_save_path=base_dir, callbacks=[checkpoint_callback],\n",
    "                                                            # StochasticWeightAveraging(swa_lrs=1e-2)],\n",
    "                    enable_progress_bar=False, logger=logger)\n",
    "\n",
    "        # gradient_clip_val=0.25\n",
    "\n",
    "        # This is the model itself, which is extended from pytorch_lightning\n",
    "        model = Explainer(n_concepts=n_concepts, n_classes=n_classes, l1=1e-3, lr=0.001,\n",
    "                        explainer_hidden=[20, 40, 20], temperature=0.7)\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        # print(f\"Gamma: {model.model[0].concept_mask}\")\n",
    "        model.freeze()\n",
    "\n",
    "        # Precision, Recall, F1\n",
    "        y_pred = torch.argmax(model(x_test), axis=1)\n",
    "        y_test_argmax = torch.argmax(y_test, axis=1)\n",
    "\n",
    "        scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                recall_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                precision_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro')]\n",
    "\n",
    "        print(f\"Before loading best: {scores}\")\n",
    "\n",
    "        scores_list.append(scores)\n",
    "    \n",
    "        model = model.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "\n",
    "        \n",
    "\n",
    "        # Precision, Recall, F1\n",
    "        # print(model(x_test))\n",
    "        y_pred = torch.argmax(model(x_test), axis=1)\n",
    "        # print(y_pred)\n",
    "        y_test_argmax = torch.argmax(y_test, axis=1)\n",
    "\n",
    "        scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                recall_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), \n",
    "                precision_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro')]\n",
    "\n",
    "        print(f\"{file} split {split+1} scores: {scores}\")\n",
    "\n",
    "        print(\"\\nTesting...\\n\")\n",
    "        model_results = trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "        scores_list.append(scores)\n",
    "\n",
    "\n",
    "        print(\"\\nExplaining\\n\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            results, f = explain_with_timeout(model, val_data=val_loader, train_data=train_loader, test_data=test_loader,\n",
    "                                        topk_expl=10,\n",
    "                                        concepts=data.columns)\n",
    "\n",
    "        except FunctionTimedOut:\n",
    "            print(\"Explanation timed out, skipping...\")\n",
    "            # explanations_list.append(None)\n",
    "            # results_list.append(None)\n",
    "            continue\n",
    "\n",
    "        end = time.time()\n",
    "        # explanations_list.append(f)\n",
    "\n",
    "        print(f\"Explaining time: {end - start}\")\n",
    "        results['model_accuracy'] = model_results[0]['test_acc_epoch']\n",
    "        results['extraction_time'] = end - start\n",
    "\n",
    "        results_list.append(results)\n",
    "        extracted_concepts = []\n",
    "        all_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "        common_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "        for j in range(n_classes):\n",
    "            # print(f[j]['explanation'])\n",
    "            n_used_concepts = sum(model.model[0].concept_mask[j] > 0.5)\n",
    "            print(f\"Number of features that impact on target {j}: {n_used_concepts}\")\n",
    "            print(f\"Explanation for target {j}: {f[j]['explanation']}\")\n",
    "            print(f\"Explanation accuracy: {f[j]['explanation_accuracy']}\")\n",
    "            explanations[j].append(f[j]['explanation'])\n",
    "            extracted_concepts.append(n_used_concepts)\n",
    "            all_concepts += model.model[0].concept_mask[j] > 0.5\n",
    "            common_concepts *= model.model[0].concept_mask[j] > 0.5\n",
    "\n",
    "        explanations_list.append(explanations)\n",
    "\n",
    "        results['extracted_concepts'] = np.mean(extracted_concepts)\n",
    "        results['common_concepts_ratio'] = sum(common_concepts) / sum(all_concepts)\n",
    "\n",
    "        \n",
    "\n",
    "        prec_rec = precision_recall(y_pred, y_test_argmax, num_classes = n_classes)\n",
    "\n",
    "        print(prec_rec)\n",
    "\n",
    "        # compare against standard feature selection\n",
    "        i_mutual_info = mutual_info_classif(x_trainval, y_trainval[:, 1])\n",
    "        i_chi2 = chi2(x_trainval, y_trainval[:, 1])[0]\n",
    "        i_chi2[np.isnan(i_chi2)] = 0\n",
    "        lasso = LassoCV(cv=5, random_state=0).fit(x_trainval, y_trainval[:, 1])\n",
    "        i_lasso = np.abs(lasso.coef_)\n",
    "        i_mu = model.model[0].concept_mask[1]\n",
    "        # print(model.model[0].concept_mask)\n",
    "        df = pd.DataFrame(np.hstack([\n",
    "            i_mu.numpy(),\n",
    "            # i_mutual_info / np.max(i_mutual_info),\n",
    "            # i_chi2 / np.max(i_chi2),\n",
    "            # i_lasso / np.max(i_lasso),\n",
    "        ]).T, columns=['feature importance'])\n",
    "        df['method'] = 'explainer'\n",
    "        # df.iloc[90:, 1] = 'MI'\n",
    "        # df.iloc[180:, 1] = 'CHI2'\n",
    "        # df.iloc[270:, 1] = 'Lasso'\n",
    "        df['feature'] = np.hstack([np.arange(0, n_concepts)])\n",
    "        feature_selection.append(df)\n",
    "\n",
    "        splitResults = [results['model_accuracy'], results['extraction_time'], *scores, f]\n",
    "\n",
    "        splitResults_list.append(splitResults)\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "    results_dict[file] = splitResults_list\n",
    "\n",
    "# results_dict[file] = [results['model_accuracy'], results['extraction_time'], *scores, f]\n",
    "# self.feature_selection = feature_selection\n",
    "# # print(self.feature_selection)\n",
    "\n",
    "# self.df = df\n",
    "# self.explanations = explanations\n",
    "# self.results_list = results_list\n",
    "# print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['staticDataSimple.csv'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>extraction_time</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>target_class_0</th>\n",
       "      <th>explanation_accuracy_0</th>\n",
       "      <th>explanation_fidelity_0</th>\n",
       "      <th>explanation_complexity_0</th>\n",
       "      <th>target_class_1</th>\n",
       "      <th>explanation_accuracy_1</th>\n",
       "      <th>explanation_fidelity_1</th>\n",
       "      <th>explanation_complexity_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>staticDataSimple.csv</th>\n",
       "      <td>0.73289</td>\n",
       "      <td>270.052255</td>\n",
       "      <td>0.579786</td>\n",
       "      <td>0.635167</td>\n",
       "      <td>0.577061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439353</td>\n",
       "      <td>0.668251</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510636</td>\n",
       "      <td>0.748099</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_accuracy  extraction_time        f1    recall  \\\n",
       "file                                                                        \n",
       "staticDataSimple.csv         0.73289       270.052255  0.579786  0.635167   \n",
       "\n",
       "                      precision  target_class_0  explanation_accuracy_0  \\\n",
       "file                                                                      \n",
       "staticDataSimple.csv   0.577061             0.0                0.439353   \n",
       "\n",
       "                      explanation_fidelity_0  explanation_complexity_0  \\\n",
       "file                                                                     \n",
       "staticDataSimple.csv                0.668251                       7.0   \n",
       "\n",
       "                      target_class_1  explanation_accuracy_1  \\\n",
       "file                                                           \n",
       "staticDataSimple.csv             1.0                0.510636   \n",
       "\n",
       "                      explanation_fidelity_1  explanation_complexity_1  \n",
       "file                                                                    \n",
       "staticDataSimple.csv                0.748099                      29.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best explanations on minority class:\n",
      "\n",
      "staticDataSimple.csv:\n",
      "\n",
      "[{'target_class': 0, 'explanation': '~los_low | (comorbidity_low & sofa_low) | (comorbidity_low & ~sofa_high) | (respiration_high & ~sofa_high)', 'explanation_accuracy': 0.4393528594065987, 'explanation_fidelity': 0.6682509505703422, 'explanation_complexity': 7}, {'target_class': 1, 'explanation': '(comorbidity_high & liver_medium & ~coagulation_medium & ~cns_high & ~gender_female) | (age_high & sofa_high & ~coagulation_medium & ~cns_high & ~cns_low & ~cns_medium & ~gender_female) | (los_low & age_high & sofa_high & ~respiration_low & ~coagulation_high & ~coagulation_medium & ~cns_high & ~gender_female) | (los_low & age_high & sofa_high & ~respiration_low & ~coagulation_medium & ~renal_low & ~cns_high & ~cns_medium & ~gender_female)', 'explanation_accuracy': 0.5106361579079709, 'explanation_fidelity': 0.7480988593155894, 'explanation_complexity': 29}]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "kFoldMeans = []\n",
    "\n",
    "bestExplanationsDict = {f:[0,0] for f in results_dict.keys()}\n",
    "\n",
    "# print(bestExplanationsDict)\n",
    "\n",
    "for x in results_dict:\n",
    "\n",
    "    cols = ['file']\n",
    "\n",
    "    cols.extend(['model_accuracy', 'extraction_time', 'f1', 'recall', 'precision'])\n",
    "\n",
    "    for idx, d in enumerate(results_dict[x][0][5]):\n",
    "        cols.extend([str(x) + \"_\" + str(idx) for x in d])\n",
    "\n",
    "    # print(cols)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for split in results_dict[x]:\n",
    "\n",
    "\n",
    "        if split[5][1]['explanation_accuracy'] > bestExplanationsDict[x][0]:\n",
    "            bestExplanationsDict[x] = [split[2], split[5]]\n",
    "\n",
    "        row = [x]\n",
    "\n",
    "        row.extend(split[:5])\n",
    "\n",
    "\n",
    "        for d in split[5]:\n",
    "\n",
    "            row.extend(d.values())\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(columns=cols, data=rows)\n",
    "\n",
    "    df = df.set_index('file')\n",
    "\n",
    "    combinedCols = list(df.describe().columns)\n",
    "\n",
    "    # print(combinedCols)\n",
    "\n",
    "    row = [x]\n",
    "    row.extend(df.describe().loc['mean'].values)\n",
    "\n",
    "    kFoldMeans.append(row)\n",
    "\n",
    "# print(kFoldMeans)\n",
    "\n",
    "\n",
    "\n",
    "kFoldMeansCols = list(df.describe().columns)\n",
    "\n",
    "combinedCols.insert(0, \"file\")\n",
    "\n",
    "\n",
    "# print(kFoldMeansCols)\n",
    "\n",
    "totalMeans = pd.DataFrame(columns=combinedCols, data=kFoldMeans)\n",
    "\n",
    "totalMeans = totalMeans.set_index('file')\n",
    "\n",
    "display(totalMeans)\n",
    "\n",
    "print(\"Best explanations on minority class:\\n\")\n",
    "for i in bestExplanationsDict:\n",
    "    print(f\"{i}:\\n\")\n",
    "    print(bestExplanationsDict[i][1])\n",
    "\n",
    "totalMeans.to_csv(f\"./processingCache/totalMeans{date.today()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25104/1571665904.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in results_dict:\n",
    "    print(file)\n",
    "\n",
    "    feature_selection = results_dict[file][2]\n",
    "    explanations = results_dict[file][3][0]\n",
    "\n",
    "    base_dir = f'./results/mimicLEN/explainer'\n",
    "\n",
    "    consistencies = []\n",
    "    # print(explanations)\n",
    "    for j in range(n_classes):\n",
    "        if explanations[j][0] is None:\n",
    "            continue\n",
    "        consistencies.append(formula_consistency(explanations[j]))\n",
    "    explanation_consistency = np.mean(consistencies)\n",
    "\n",
    "    concat_feature_selection = pd.concat(feature_selection, axis=0)\n",
    "\n",
    "    # print(\"Feature selection: \", feature_selection)\n",
    "\n",
    "    f1 = concat_feature_selection[concat_feature_selection['feature'] <= n_concepts//3]\n",
    "    f2 = concat_feature_selection[(concat_feature_selection['feature'] > n_concepts//3) & (concat_feature_selection['feature'] <= (n_concepts*2)//3)]\n",
    "    f3 = concat_feature_selection[concat_feature_selection['feature'] > (n_concepts*2)//3]\n",
    "\n",
    "    sets = [f1, f2, f3]\n",
    "\n",
    "    fig = plt.figure(figsize=[30, 10])\n",
    "    fig.suptitle(\"Feature Importance\")\n",
    "\n",
    "    # print(sets)\n",
    "\n",
    "    for i in range(len(sets)):\n",
    "        f = sets[i]\n",
    "\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        # print(f.iloc[:, 0][f.iloc[:, 0] != False])\n",
    "\n",
    "        # sums = [featureDF['feature importance'].sum() for _, featureDF in f.groupby('feature')]\n",
    "        # print(len(sums))\n",
    "        # print(len(f['feature']))\n",
    "\n",
    "        ax = sns.barplot(y=data.columns[f['feature']], x=f.iloc[:,0], orient='h', hue=f['method'], errwidth=0.5, ci=None)\n",
    "                        # hue=f['method'],  , errcolor='k')\n",
    "        ax.set(xlim=(0,0.5))\n",
    "        ax.set_title(\"\")\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "    plt.xlabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(base_dir, 'barplot_mimic.png'))\n",
    "    plt.savefig(os.path.join(base_dir, 'barplot_mimic.pdf'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    results_list = [x for x in results_list if x is not None]\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    results_df['explanation_consistency'] = explanation_consistency\n",
    "    results_df.to_csv(os.path.join(base_dir, 'results_aware_mimic.csv'))\n",
    "    results_df\n",
    "\n",
    "\n",
    "results_df.mean()\n",
    "\n",
    "results_df.sem()\n",
    "\n",
    "x = dataTensor\n",
    "y = targetTensor\n",
    "\n",
    "dt_scores, rf_scores = [], []\n",
    "for split, (trainval_index, test_index) in enumerate(\n",
    "        skf.split(x.cpu().detach().numpy(), y.argmax(dim=1).cpu().detach().numpy())):\n",
    "    print(f'Split [{split + 1}/{n_splits}]')\n",
    "    x_trainval, x_test = x[trainval_index], x[test_index]\n",
    "    y_trainval, y_test = y[trainval_index].argmax(dim=1), y[test_index].argmax(dim=1)\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(max_depth=5, random_state=split)\n",
    "    dt_model.fit(x_trainval, y_trainval)\n",
    "    dt_scores.append(dt_model.score(x_test, y_test))\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state=split)\n",
    "    rf_model.fit(x_trainval, y_trainval)\n",
    "    rf_scores.append(rf_model.score(x_test, y_test))\n",
    "\n",
    "print(f'Random forest scores: {np.mean(rf_scores)} (+/- {np.std(rf_scores)})')\n",
    "print(f'Decision tree scores: {np.mean(dt_scores)} (+/- {np.std(dt_scores)})')\n",
    "print(f'Mu net scores (model): {results_df[\"model_accuracy\"].mean()} (+/- {results_df[\"model_accuracy\"].std()})')\n",
    "print(f'Mu net scores (exp): {results_df[\"explanation_accuracy\"].mean()} (+/- {results_df[\"explanation_accuracy\"].std()})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 40\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:57: LightningDeprecationWarning: Setting `Trainer(weights_save_path=)` has been deprecated in v1.6 and will be removed in v1.8. Please pass ``dirpath`` directly to the `ModelCheckpoint` callback\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: ./runs/splits/clusteredData.csv\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:611: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 10.6 K\n",
      "-------------------------------------------\n",
      "10.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.6 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training clusteredData.csv\n",
      "\n",
      "tensor([0.0011, 0.0286])\n",
      "Training on 2 classes\n",
      "Num concepts: 120\n",
      "Num classes: 2\n",
      "Sizes:  (767, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.8541666865348816\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "clusteredData.csv Scores: [0.35098591549295777, 0.4193548387096774, 0.4902301346070343]\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "\n",
    "\n",
    "for file in files[:1]:\n",
    "\n",
    "    \n",
    "    print(f\"Training {file}\\n\")\n",
    "\n",
    "    data = datasets[file]\n",
    "\n",
    "    if file in [\"staticData.csv\", \"staticDataSimple.csv\"]:\n",
    "        targetName = \"deathperiod\"\n",
    "    else:\n",
    "        targetName = \"Mortality14Days\"\n",
    "\n",
    "    targetSeries = data[targetName]\n",
    "    data = data.drop(columns=[targetName])\n",
    "\n",
    "\n",
    "    dataTensor = torch.FloatTensor(data.to_numpy())\n",
    "    targetTensor = one_hot(torch.tensor(targetSeries.values).to(torch.long)).to(torch.float)\n",
    "\n",
    "\n",
    "    dataset = TensorDataset(dataTensor, targetTensor)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "\n",
    "    val_size = (len(dataset) - train_size) // 2\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    class_count = targetSeries.value_counts().values\n",
    "    weights = 1 / torch.Tensor(class_count)\n",
    "\n",
    "    print(weights)\n",
    "\n",
    "    sampler = WeightedRandomSampler(weights, train_size)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=train_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=test_size)\n",
    "\n",
    "\n",
    "\n",
    "    n_concepts = dataTensor.shape[1]\n",
    "    # self.n_concepts = n_concepts\n",
    "\n",
    "\n",
    "    n_classes = targetTensor.shape[1]\n",
    "    # self.n_classes = n_classes\n",
    "\n",
    "    print(\"Training on {} classes\".format(n_classes))\n",
    "\n",
    "    print(\"Num concepts: {}\".format(n_concepts))\n",
    "    print(\"Num classes: {}\".format(n_classes))\n",
    "\n",
    "    base_dir = f'./results/mimicLEN/explainer'\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    seed_everything(40)\n",
    "\n",
    "    # n_splits = 10\n",
    "\n",
    "    # self.n_splits = n_splits\n",
    "\n",
    "    # skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # self.skf = skf\n",
    "\n",
    "    results_list = []\n",
    "    feature_selection = []\n",
    "    explanations = {i: [] for i in range(n_classes)}\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # x = dataTensor\n",
    "    # y = targetTensor\n",
    "        \n",
    "\n",
    "    # x_trainval, x_test = torch.FloatTensor(dataTensor[trainval_index]), torch.FloatTensor(dataTensor[test_index])\n",
    "    # y_trainval, y_test = torch.FloatTensor(y[trainval_index]), torch.FloatTensor(y[test_index])\n",
    "    # x_train_unbalanced, x_val, y_train_unbalanced, y_val = train_test_split(x_trainval, y_trainval, test_size=0.2, random_state=42)\n",
    "    # print(f'{len(y_train_unbalanced)}/{len(y_val)}/{len(y_test)}')\n",
    "\n",
    "\n",
    "    # # Rebalancing training set\n",
    "    # # obj = imblearn.over_sampling.SMOTEN(random_state=0, n_jobs=4)\n",
    "\n",
    "    # # print(sorted(Counter(torch.argmax(y_train_unbalanced, axis=1).numpy()).items()))\n",
    "\n",
    "    # x_train, y_train = x_train_unbalanced.numpy(), torch.argmax(y_train_unbalanced, axis=1).numpy()\n",
    "\n",
    "    # print(sorted(Counter(y_train).items()))\n",
    "\n",
    "    # class_count = pd.Series(np.argmax(y_train_unbalanced.numpy(), axis=1)).value_counts().values\n",
    "    # weights = 1 / torch.FloatTensor(class_count)\n",
    "\n",
    "    # print(\"Weights: {}\".format(weights))\n",
    "\n",
    "    # sampler = WeightedRandomSampler(weights, train_size)\n",
    "\n",
    "    # y_train = one_hot(torch.tensor(y_train).to(torch.long)).to(torch.float)\n",
    "    # x_train = torch.FloatTensor(x_train)\n",
    "\n",
    "    \n",
    "\n",
    "    # train_data = TensorDataset(x_train, y_train)\n",
    "    # val_data = TensorDataset(x_val, y_val)\n",
    "    # test_data = TensorDataset(x_test, y_test)\n",
    "    # train_loader = DataLoader(train_data, batch_size=train_size, sampler=sampler)\n",
    "    # val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "    # test_loader = DataLoader(test_data, batch_size=test_size)\n",
    "\n",
    "    print(\"Sizes: \", (train_size, test_size, val_size))\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(dirpath=base_dir, monitor='val_acc', save_top_k=3)\n",
    "\n",
    "    # Constructs the way that the model will be trained\n",
    "    logger = TensorBoardLogger(\"./runs/splits/\", name=file)\n",
    "\n",
    "    # Constructs the way that the model will be trained\n",
    "    trainer = Trainer(max_epochs=400, gpus=1, auto_lr_find=True, deterministic=True,\n",
    "                    check_val_every_n_epoch=1, default_root_dir=base_dir,\n",
    "                    weights_save_path=base_dir, callbacks=[checkpoint_callback, StochasticWeightAveraging(swa_lrs=1e-2)], \n",
    "                    enable_progress_bar=False, log_every_n_steps=1, logger=logger,\n",
    "                    gradient_clip_val=0.5)\n",
    "\n",
    "    # This is the model itself, which is extended from pytorch_lightning\n",
    "    model = Explainer(n_concepts=n_concepts, n_classes=n_classes, l1=1e-3, lr=0.001,\n",
    "                    explainer_hidden=[30, 40, 30, 20, 10], temperature=0.7)\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    # print(f\"Gamma: {model.model[0].concept_mask}\")\n",
    "    model.freeze()\n",
    "\n",
    "    model = model.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "\n",
    "    print(\"\\nTesting...\\n\")\n",
    "    model_results = trainer.test(model, dataloaders=test_loader)\n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "    x_test, y_test = next(iter(test_loader))\n",
    "    y_pred = torch.argmax(model(x_test), axis=1)\n",
    "    y_test_argmax = torch.argmax(y_test, axis=1)\n",
    "\n",
    "    scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), recall_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), precision_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro')]\n",
    "\n",
    "    print(f\"{file} Scores: {scores}\")\n",
    "\n",
    "    print(\"\\nExplaining\\n\")\n",
    "    \n",
    "    continue\n",
    "\n",
    "    try:\n",
    "\n",
    "        results, f = explain_with_timeout(model, val_data=test_loader, train_data=train_loader, test_data=test_loader,\n",
    "                                    topk_expl=10,\n",
    "                                    concepts=data.columns)\n",
    "    except FunctionTimedOut:\n",
    "        print(\"Explanation timed out, skipping...\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Explaining time: {end - start}\")\n",
    "    results['model_accuracy'] = model_results[0]['test_acc_epoch']\n",
    "    results['extraction_time'] = end - start\n",
    "\n",
    "    # results_list.append(results)\n",
    "    extracted_concepts = []\n",
    "    all_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "    common_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "    for j in range(n_classes):\n",
    "        # print(f[j]['explanation'])\n",
    "        n_used_concepts = sum(model.model[0].concept_mask[j] > 0.5)\n",
    "        print(f\"Number of features that impact on target {j}: {n_used_concepts}\")\n",
    "        print(f\"Explanation for target {j}: {f[j]['explanation']}\")\n",
    "        print(f\"Explanation accuracy: {f[j]['explanation_accuracy']}\")\n",
    "        explanations[j].append(f[j]['explanation'])\n",
    "        extracted_concepts.append(n_used_concepts)\n",
    "        all_concepts += model.model[0].concept_mask[j] > 0.5\n",
    "        common_concepts *= model.model[0].concept_mask[j] > 0.5\n",
    "\n",
    "    # explanations_list.append(explanations)\n",
    "\n",
    "    results['extracted_concepts'] = np.mean(extracted_concepts)\n",
    "    results['common_concepts_ratio'] = sum(common_concepts) / sum(all_concepts)\n",
    "\n",
    "    \n",
    "\n",
    "    # compare against standard feature selection\n",
    "    i_mutual_info = mutual_info_classif(x_test, y_test[:, 1])\n",
    "    i_chi2 = chi2(x_test, y_test[:, 1])[0]\n",
    "    i_chi2[np.isnan(i_chi2)] = 0\n",
    "    lasso = LassoCV(cv=5, random_state=0).fit(x_test, y_test[:, 1])\n",
    "    i_lasso = np.abs(lasso.coef_)\n",
    "    i_mu = model.model[0].concept_mask[1]\n",
    "    # print(model.model[0].concept_mask)\n",
    "    df = pd.DataFrame(np.hstack([\n",
    "        i_mu.numpy(),\n",
    "        # i_mutual_info / np.max(i_mutual_info),\n",
    "        # i_chi2 / np.max(i_chi2),\n",
    "        # i_lasso / np.max(i_lasso),\n",
    "    ]).T, columns=['feature importance'])\n",
    "    df['method'] = 'explainer'\n",
    "    # df.iloc[90:, 1] = 'MI'\n",
    "    # df.iloc[180:, 1] = 'CHI2'\n",
    "    # df.iloc[270:, 1] = 'Lasso'\n",
    "    df['feature'] = np.hstack([np.arange(0, n_concepts)])\n",
    "    feature_selection.append(df)\n",
    "\n",
    "\n",
    "    results_dict[file] = [results['model_accuracy'], results['extraction_time'], *scores, f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 40\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:57: LightningDeprecationWarning: Setting `Trainer(weights_save_path=)` has been deprecated in v1.6 and will be removed in v1.8. Please pass ``dirpath`` directly to the `ModelCheckpoint` callback\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:611: UserWarning: Checkpoint directory C:\\Users\\benma\\OneDrive\\Kings\\Modules\\Term 2\\Individual Project\\LEN Individual Project\\Static\\results\\mimicLEN\\explainer exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | loss  | CrossEntropyLoss | 0     \n",
      "1 | model | Sequential       | 2.1 K \n",
      "-------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training clusteredData.csv\n",
      "\n",
      "0.0    744\n",
      "1.0     23\n",
      "dtype: int64\n",
      "tensor([0.0013, 0.0435])\n",
      "tensor([0.0278, 0.3333])\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "Training on 2 classes\n",
      "Num concepts: 50\n",
      "Num classes: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1933: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5353685778108711, 0.7, 0.5567226890756303]\n",
      "\n",
      "Testing...\n",
      "\n",
      "[0.5425957690108634, 0.7055555555555555, 0.5595813204508857]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.6797385811805725\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Explaining\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benma\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "for file in files[:1]:\n",
    "\n",
    "    \n",
    "    print(f\"Training {file}\\n\")\n",
    "\n",
    "    data = datasets[file]\n",
    "\n",
    "    if file in [\"staticData.csv\", \"staticDataSimple.csv\"]:\n",
    "        targetName = \"deathperiod\"\n",
    "    else:\n",
    "        targetName = \"Mortality14Days\"\n",
    "\n",
    "    targetSeries = data[targetName]\n",
    "    data = data.drop(columns=[targetName])\n",
    "\n",
    "\n",
    "    dataTensor = torch.FloatTensor(data.to_numpy())\n",
    "    targetTensor = (torch.tensor(targetSeries.values).to(torch.long)).to(torch.float)\n",
    "\n",
    "\n",
    "    dataset = TensorDataset(dataTensor, targetTensor)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "\n",
    "    val_size = (len(dataset) - train_size) // 2\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    x_train_unbalanced, x_temp, y_train_unbalanced, y_temp = train_test_split(dataTensor, targetTensor, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "    class_count = pd.Series(y_train_unbalanced.numpy()).value_counts()\n",
    "    print(class_count)\n",
    "    t_weights = 1 / torch.Tensor(class_count.values)\n",
    "\n",
    "    print(t_weights)\n",
    "\n",
    "    # print(y_train_unbalanced.numpy().astype(np.int64))\n",
    "\n",
    "    train_weights = np.array([weights[t] for t in y_train_unbalanced.numpy().astype(np.int64)])\n",
    "\n",
    "    # print(samples_weight)\n",
    "\n",
    "    train_sampler = WeightedRandomSampler(train_weights, len(y_train_unbalanced), replacement=True)\n",
    "\n",
    "\n",
    "\n",
    "    class_count = pd.Series(y_val.numpy()).value_counts()\n",
    "    # print(class_count)\n",
    "    v_weights = 1 / torch.Tensor(class_count.values)\n",
    "    val_weights = np.array([v_weights[t] for t in y_val.numpy().astype(np.int64)])\n",
    "\n",
    "    print(v_weights)\n",
    "\n",
    "    val_sampler = WeightedRandomSampler(val_weights, len(y_val.numpy()), replacement=True)\n",
    "\n",
    "    # Rebalancing training set\n",
    "    # obj = imblearn.over_sampling.SMOTEN(random_state=0, n_jobs=4)\n",
    "\n",
    "    # print(sorted(Counter(y_train_unbalanced.numpy()).items()))\n",
    "\n",
    "    # x_train, y_train = obj.fit_resample(x_train_unbalanced.numpy(), y_train_unbalanced.numpy())\n",
    "\n",
    "    # print(sorted(Counter(y_train).items()))\n",
    "\n",
    "    targetTensor = one_hot(torch.Tensor(y_train_unbalanced).to(torch.long)).to(torch.float)\n",
    "\n",
    "\n",
    "    print(targetTensor)\n",
    "\n",
    "    y_val = one_hot(torch.Tensor(y_val).to(torch.long)).to(torch.float)\n",
    "\n",
    "    y_test = one_hot(torch.Tensor(y_test).to(torch.long)).to(torch.float)\n",
    "\n",
    "    x_train = torch.FloatTensor(x_train_unbalanced)\n",
    "    x_val = torch.FloatTensor(x_val)\n",
    "\n",
    "    x_test = torch.FloatTensor(x_test)\n",
    "\n",
    "\n",
    "    train_data = TensorDataset(x_train, targetTensor)\n",
    "    val_data = TensorDataset(x_val, y_val)\n",
    "    test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=train_size, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=test_size)\n",
    "\n",
    "    n_concepts = dataTensor.shape[1]\n",
    "    # self.n_concepts = n_concepts\n",
    "\n",
    "\n",
    "    n_classes = targetTensor.shape[1]\n",
    "    # self.n_classes = n_classes\n",
    "\n",
    "    print(\"Training on {} classes\".format(n_classes))\n",
    "\n",
    "    print(\"Num concepts: {}\".format(n_concepts))\n",
    "    print(\"Num classes: {}\".format(n_classes))\n",
    "\n",
    "    base_dir = f'./results/mimicLEN/explainer'\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    seed_everything(40)\n",
    "\n",
    "    n_splits = 10\n",
    "\n",
    "    # self.n_splits = n_splits\n",
    "\n",
    "    # skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # self.skf = skf\n",
    "\n",
    "    results_list = []\n",
    "    feature_selection = []\n",
    "    explanations = {i: [] for i in range(n_classes)}\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    x = dataTensor\n",
    "    y = targetTensor\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # x_trainval, x_test = torch.FloatTensor(x[trainval_index]), torch.FloatTensor(x[test_index])\n",
    "    # y_trainval, y_test = torch.FloatTensor(y[trainval_index]), torch.FloatTensor(y[test_index])\n",
    "    # x_train_unbalanced, x_val, y_train_unbalanced, y_val = train_test_split(dataTensor, targetTensor, test_size=0.2, random_state=42)\n",
    "    # print(f'{len(y_train_unbalanced)}/{len(y_val)}/{len(y_test)}')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # y_train = one_hot(torch.tensor(y_train).to(torch.long)).to(torch.float)\n",
    "    # x_train = torch.FloatTensor(x_train)\n",
    "\n",
    "    # train_data = TensorDataset(x_train, y_train)\n",
    "    # val_data = TensorDataset(x_val, y_val)\n",
    "    # test_data = TensorDataset(x_test, y_test)\n",
    "    # train_loader = DataLoader(train_data, batch_size=train_size)\n",
    "    # val_loader = DataLoader(val_data, batch_size=val_size)\n",
    "    # test_loader = DataLoader(test_data, batch_size=test_size)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(dirpath=base_dir, monitor='val_loss', mode='min', save_top_k=1)\n",
    "\n",
    "    logger = TensorBoardLogger(\"./runs/splits/\", name=file)\n",
    "\n",
    "    # Constructs the way that the model will be trained\n",
    "    trainer = Trainer(max_epochs=1600, gpus=1, auto_lr_find=True, deterministic=True,\n",
    "                    check_val_every_n_epoch=1, default_root_dir=base_dir,\n",
    "                    weights_save_path=base_dir, callbacks=[checkpoint_callback],\n",
    "                                                            # StochasticWeightAveraging(swa_lrs=1e-2)],\n",
    "                    enable_progress_bar=False, logger=logger, gradient_clip_val=0.25)\n",
    "\n",
    "    # This is the model itself, which is extended from pytorch_lightning\n",
    "    model = Explainer(n_concepts=n_concepts, n_classes=n_classes, l1=1e-3, lr=0.0001,\n",
    "                    explainer_hidden=[20], temperature=0.7)\n",
    "\n",
    "    start = time.time()\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    # print(f\"Gamma: {model.model[0].concept_mask}\")\n",
    "    model.freeze()\n",
    "\n",
    "    x_test, y_test = next(iter(test_loader))\n",
    "    y_pred = torch.argmax(model(x_test), axis=1)\n",
    "    # print(\"Predictions:\", y_pred)\n",
    "    y_test_argmax = torch.argmax(y_test, axis=1)\n",
    "    # print(\"Actual:\", y_test_argmax)\n",
    "\n",
    "    scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), recall_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), precision_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro')]\n",
    "\n",
    "    print(scores)\n",
    "\n",
    "    model = model.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "\n",
    "    print(\"\\nTesting...\\n\")\n",
    "\n",
    "    x_test, y_test = next(iter(test_loader))\n",
    "    y_pred = torch.argmax(model(x_test), axis=1)\n",
    "    # print(\"Predictions:\", y_pred)\n",
    "    y_test_argmax = torch.argmax(y_test, axis=1)\n",
    "    # print(\"Actual:\", y_test_argmax)\n",
    "\n",
    "    scores = [f1_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), recall_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro'), precision_score(y_test_argmax.numpy(), y_pred.numpy(), average='macro')]\n",
    "\n",
    "    print(scores)\n",
    "\n",
    "    model_results = trainer.test(model, dataloaders=test_loader)\n",
    "    \n",
    "    print(\"\\nExplaining\\n\")\n",
    "    \n",
    "    break\n",
    "    \n",
    "    try:\n",
    "\n",
    "        results, f = explain_with_timeout(model, val_data=test_loader, train_data=train_loader, test_data=test_loader,\n",
    "                                    topk_expl=10,\n",
    "                                    concepts=data.columns)\n",
    "    except FunctionTimedOut:\n",
    "        print(\"Explanation timed out, skipping...\")\n",
    "        results_list.append(None)\n",
    "        continue\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Explaining time: {end - start}\")\n",
    "    results['model_accuracy'] = model_results[0]['test_acc_epoch']\n",
    "    results['extraction_time'] = end - start\n",
    "\n",
    "    # results_list.append(results)\n",
    "    extracted_concepts = []\n",
    "    all_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "    common_concepts = model.model[0].concept_mask[0] > 0.5\n",
    "    for j in range(n_classes):\n",
    "        # print(f[j]['explanation'])\n",
    "        n_used_concepts = sum(model.model[0].concept_mask[j] > 0.5)\n",
    "        print(f\"Number of features that impact on target {j}: {n_used_concepts}\")\n",
    "        print(f\"Explanation for target {j}: {f[j]['explanation']}\")\n",
    "        print(f\"Explanation accuracy: {f[j]['explanation_accuracy']}\")\n",
    "        explanations[j].append(f[j]['explanation'])\n",
    "        extracted_concepts.append(n_used_concepts)\n",
    "        all_concepts += model.model[0].concept_mask[j] > 0.5\n",
    "        common_concepts *= model.model[0].concept_mask[j] > 0.5\n",
    "\n",
    "    # explanations_list.append(explanations)\n",
    "\n",
    "    # results['extracted_concepts'] = np.mean(extracted_concepts)\n",
    "    # results['common_concepts_ratio'] = sum(common_concepts) / sum(all_concepts)\n",
    "\n",
    "    # # Precision, Recall, F1\n",
    "    # # print(x_test)\n",
    "    \n",
    "    # # print(f\"{file} split {split+1} scores: {scores}\")\n",
    "\n",
    "    # # compare against standard feature selection\n",
    "    # i_mutual_info = mutual_info_classif(x_test, y_test[:, 1])\n",
    "    # i_chi2 = chi2(x_test, y_test[:, 1])[0]\n",
    "    # i_chi2[np.isnan(i_chi2)] = 0\n",
    "    # lasso = LassoCV(cv=5, random_state=0).fit(x_test, y_test[:, 1])\n",
    "    # i_lasso = np.abs(lasso.coef_)\n",
    "    # i_mu = model.model[0].concept_mask[1]\n",
    "    # # print(model.model[0].concept_mask)\n",
    "    # df = pd.DataFrame(np.hstack([\n",
    "    #     i_mu.numpy(),\n",
    "    #     # i_mutual_info / np.max(i_mutual_info),\n",
    "    #     # i_chi2 / np.max(i_chi2),\n",
    "    #     # i_lasso / np.max(i_lasso),\n",
    "    # ]).T, columns=['feature importance'])\n",
    "    # df['method'] = 'explainer'\n",
    "    # # df.iloc[90:, 1] = 'MI'\n",
    "    # # df.iloc[180:, 1] = 'CHI2'\n",
    "    # # df.iloc[270:, 1] = 'Lasso'\n",
    "    # df['feature'] = np.hstack([np.arange(0, n_concepts)])\n",
    "    # feature_selection.append(df)\n",
    "\n",
    "\n",
    "    results_dict[file] = [results['model_accuracy'], results['extraction_time'], *scores, f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0]\n",
      " Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "minority class correct %: 10.0\n"
     ]
    }
   ],
   "source": [
    "# If it doesn't learn on clusterData, the code is probably wrong. Check rebalancing is hooked up.\n",
    "\n",
    "x, y = next(iter(test_loader))\n",
    "\n",
    "y_argmax = np.argmax(y.numpy(), axis=1)\n",
    "\n",
    "y_hat = model(x)\n",
    "\n",
    "y_hat = np.argmax(y_hat.detach().numpy(), axis=1)\n",
    "\n",
    "y = np.argmax(y.numpy(), axis=1)\n",
    "\n",
    "print(f\"Predicted: {y_hat}\\n Actual: {y}\")\n",
    "\n",
    "minCorrect = [y_hat[i] == y[i] if y_hat[i] == 1 else False for i in range(len(y_hat))]\n",
    "\n",
    "print(\"minority class correct %:\", 100*np.sum(minCorrect) / np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5425957690108634, 0.7055555555555555, 0.5595813204508857]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scores = [f1_score(y_argmax, y_hat, average='macro'), recall_score(y_argmax, y_hat, average='macro'), precision_score(y_argmax, y_hat, average='macro')]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file', 'model_accuracy', 'extraction_time', 'target_class_0', 'explanation_0', 'explanation_accuracy_0', 'explanation_fidelity_0', 'explanation_complexity_0', 'target_class_1', 'explanation_1', 'explanation_accuracy_1', 'explanation_fidelity_1', 'explanation_complexity_1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>extraction_time</th>\n",
       "      <th>target_class_0</th>\n",
       "      <th>explanation_0</th>\n",
       "      <th>explanation_accuracy_0</th>\n",
       "      <th>explanation_fidelity_0</th>\n",
       "      <th>explanation_complexity_0</th>\n",
       "      <th>target_class_1</th>\n",
       "      <th>explanation_1</th>\n",
       "      <th>explanation_accuracy_1</th>\n",
       "      <th>explanation_fidelity_1</th>\n",
       "      <th>explanation_complexity_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clusteredData.csv</th>\n",
       "      <td>0.9375</td>\n",
       "      <td>50.876622</td>\n",
       "      <td>0</td>\n",
       "      <td>SVRI_Mean_medium | ~CVP_StdDev_high</td>\n",
       "      <td>0.631545</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>~Arterial BP [Diastolic]_Mean_very_low &amp; ~Arte...</td>\n",
       "      <td>0.428231</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_accuracy  extraction_time  target_class_0  \\\n",
       "file                                                                 \n",
       "clusteredData.csv          0.9375        50.876622               0   \n",
       "\n",
       "                                         explanation_0  \\\n",
       "file                                                     \n",
       "clusteredData.csv  SVRI_Mean_medium | ~CVP_StdDev_high   \n",
       "\n",
       "                   explanation_accuracy_0  explanation_fidelity_0  \\\n",
       "file                                                                \n",
       "clusteredData.csv                0.631545                0.911458   \n",
       "\n",
       "                   explanation_complexity_0  target_class_1  \\\n",
       "file                                                          \n",
       "clusteredData.csv                         2               1   \n",
       "\n",
       "                                                       explanation_1  \\\n",
       "file                                                                   \n",
       "clusteredData.csv  ~Arterial BP [Diastolic]_Mean_very_low & ~Arte...   \n",
       "\n",
       "                   explanation_accuracy_1  explanation_fidelity_1  \\\n",
       "file                                                                \n",
       "clusteredData.csv                0.428231                 0.59375   \n",
       "\n",
       "                   explanation_complexity_1  \n",
       "file                                         \n",
       "clusteredData.csv                         5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['file']\n",
    "\n",
    "cols.append('model_accuracy')\n",
    "cols.append('extraction_time')\n",
    "\n",
    "for idx, d in enumerate(results_dict['clusteredData.csv'][5]):\n",
    "    cols.extend([str(x) + \"_\" + str(idx) for x in d])\n",
    "\n",
    "print(cols)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for x in files[:1]:\n",
    "\n",
    "    row = [x]\n",
    "\n",
    "    row.extend(results_dict[x][:2])\n",
    "\n",
    "    for d in results_dict[x][5]:\n",
    "        row.extend(d.values())\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "totalDF = pd.DataFrame(columns=cols, data=rows)\n",
    "\n",
    "totalDF = totalDF.set_index('file')\n",
    "\n",
    "display(totalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF.to_csv(\"./processingCache/explainer_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c0da8f5b93ec0612bb8aed25290fce040bcd4618fccb82f778dd001cba2969b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
